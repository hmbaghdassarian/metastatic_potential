{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3553aded",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nobackup/users/hmbaghda/Software/miniforge3/envs/metastatic_potential/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pathlib\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import CmaEsSampler, TPESampler, RandomSampler\n",
    "from optuna.distributions import CategoricalDistribution\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.linear_model import ElasticNet, Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "from utils import write_pickled_object\n",
    "from utils import FeatureSelector, MeanCenterer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1ee33da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/nobackup/users/hmbaghda/metastatic_potential/'\n",
    "random_state = 888\n",
    "\n",
    "n_cores = 80\n",
    "os.environ[\"OMP_NUM_THREADS\"] = str(n_cores)\n",
    "os.environ[\"MKL_NUM_THREADS\"] = str(n_cores)\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = str(n_cores)\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = str(n_cores)\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = str(n_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c804de8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_corr_scorer(y_true, y_pred):\n",
    "    return pearsonr(y_true, y_pred)[0]\n",
    "\n",
    "class PLSRegression_X(PLSRegression):\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = super().transform(X, y)\n",
    "        if isinstance(X_transformed, tuple):\n",
    "            X_transformed = X_transformed[0]\n",
    "        return X_transformed\n",
    "    \n",
    "class HybridSampler(optuna.samplers.BaseSampler):\n",
    "    def __init__(self, primary_sampler, fallback_sampler):\n",
    "        self.primary_sampler = primary_sampler  # e.g., CmaEsSampler\n",
    "        self.fallback_sampler = fallback_sampler  # e.g., TPESampler\n",
    "\n",
    "    def infer_relative_search_space(self, study, trial):\n",
    "        # Let the primary sampler define the relative search space\n",
    "        return self.primary_sampler.infer_relative_search_space(study, trial)\n",
    "\n",
    "    def sample_relative(self, study, trial, search_space):\n",
    "        # Let the primary sampler handle relative sampling\n",
    "        return self.primary_sampler.sample_relative(study, trial, search_space)\n",
    "\n",
    "    def sample_independent(self, study, trial, param_name, param_distribution):\n",
    "        # Use the fallback sampler for unsupported parameter types\n",
    "        if isinstance(param_distribution, CategoricalDistribution):\n",
    "            return self.fallback_sampler.sample_independent(study, trial, param_name, param_distribution)\n",
    "        # Default to the primary sampler\n",
    "        return self.primary_sampler.sample_independent(study, trial, param_name, param_distribution)\n",
    "\n",
    "class RandomTPESampler(TPESampler):\n",
    "    def __init__(self, exploration_sampler, exploration_freq=20, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.exploration_sampler = exploration_sampler\n",
    "        self.exploration_freq = exploration_freq\n",
    "\n",
    "    def sample_independent(self, study, trial, param_name, param_distribution):\n",
    "        # Use the exploration_sampler periodically\n",
    "        if trial.number % self.exploration_freq == 0:\n",
    "            return self.exploration_sampler.sample_independent(study, trial, param_name, param_distribution)\n",
    "        # Default to TPE\n",
    "        return super().sample_independent(study, trial, param_name, param_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3e51d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_objective(trial, X, y, inner_cv, n_cores, random_state, model_type):\n",
    "    # Define feature reduction/selection method\n",
    "        \n",
    "    steps = [\n",
    "        (\"feature_reduction\", FeatureSelector(method=\"top_n_cv\", \n",
    "                                              n_features=trial.suggest_categorical(\"FeatureSelector__n_features\", [250, 500, 1000, 5000, X.shape[1]]))),\n",
    "        (\"mean_centering\", MeanCenterer()),\n",
    "    ]\n",
    "\n",
    "\n",
    "    # Define model\n",
    "    if model_type == \"SVR_linear\":\n",
    "        steps.append((\"model\", SVR(\n",
    "            kernel='linear',\n",
    "            C=trial.suggest_float(model_type + \"__C\", 1e-4, 1e2, log = True),\n",
    "            epsilon=trial.suggest_float(model_type + \"__epsilon\", 1e-3, 10, log=True)\n",
    "        )))\n",
    "    elif model_type == 'PLS':\n",
    "        steps.append(\n",
    "            (\"model\", PLSRegression_X(n_components=trial.suggest_int(model_type + \"__n_components\", 2, 100, step = 1))), \n",
    "        )\n",
    "    elif model_type == 'Ridge':\n",
    "        steps.append(\n",
    "            ('model', Ridge(alpha=trial.suggest_float(model_type + \"__alpha\", 1e-3, 1e2, log = True), \n",
    "                                             random_state=random_state))\n",
    "        )\n",
    "    elif model_type == 'Lasso':\n",
    "        steps.append(\n",
    "            ('model', Lasso(alpha=trial.suggest_float(model_type + \"__alpha\", 1e-3, 1e2, log = True), \n",
    "                                             random_state=random_state))\n",
    "        )\n",
    "    elif model_type == 'ElasticNet':\n",
    "        steps.append(\n",
    "            ('model', ElasticNet(alpha=trial.suggest_float(model_type + \"__alpha\", 1e-3, 1e2, log = True),\n",
    "                                 random_state=random_state, \n",
    "                                l1_ratio = trial.suggest_float(model_type + \"__l1_ratio\", 0.3, 0.7, step = 0.1)))\n",
    "        )\n",
    "    elif model_type == \"SVR_poly\":\n",
    "        steps.append((\"model\", SVR(\n",
    "            kernel='poly',\n",
    "            C=trial.suggest_float(model_type + \"__C\", 1e-4, 1e2, log = True),\n",
    "            epsilon=trial.suggest_float(model_type + \"__epsilon\", 1e-3, 10, log=True),\n",
    "            degree=trial.suggest_int(model_type + \"__degree\", 2, 5, step=1),\n",
    "            coef0=trial.suggest_float(model_type + \"__coef0\", 0, 2, step=0.1), \n",
    "            gamma=trial.suggest_categorical(model_type + \"__gamma\", ['scale', 'auto'])\n",
    "        )))\n",
    "    elif model_type == \"SVR_rbf\":\n",
    "        steps.append((\"model\", SVR(\n",
    "            kernel='rbf',\n",
    "            C=trial.suggest_float(model_type + \"__C\", 1e-4, 1e2, log = True),\n",
    "            epsilon=trial.suggest_float(model_type + \"__epsilon\", 1e-3, 10, log=True),\n",
    "            gamma=trial.suggest_categorical(model_type + \"__gamma\", ['scale', 'auto'])\n",
    "        )))\n",
    "    elif model_type == \"RFR\":\n",
    "        steps.append((\"model\", RandomForestRegressor(\n",
    "            n_estimators=trial.suggest_int(model_type + \"__n_estimators\", 300, 1600, step=400),\n",
    "            max_features=trial.suggest_categorical(model_type + \"__max_features\", [\"sqrt\", \"log2\", 0.5, 0.75, 1]),\n",
    "            max_samples=trial.suggest_categorical(model_type + \"__max_samples\", [0.25, 0.5, 0.75, None]),\n",
    "            max_depth=trial.suggest_categorical(model_type + \"__max_depth\", [None, 10, 25, 50, 100, 200]),\n",
    "            random_state=random_state,\n",
    "            n_jobs=n_cores\n",
    "        )))\n",
    "    elif model_type == \"XGBoost\":\n",
    "        steps.append((\"model\", XGB.XGBRegressor(\n",
    "            n_estimators=trial.suggest_int(model_type + \"__n_estimators\", 300, 1600, step=400),\n",
    "            max_depth=trial.suggest_categorical(model_type + \"__max_depth\", [10, 25, 50, 100, 200]),\n",
    "            learning_rate=trial.suggest_float(model_type + \"__learning_rate\", 1e-3, 1, log=True),\n",
    "            subsample=trial.suggest_float(model_type + \"__subsample\", 0.25, 1.0, step=0.05),\n",
    "            reg_alpha=trial.suggest_float(model_type + \"__reg_alpha\", 0, 10, step=0.1),\n",
    "            reg_lambda=trial.suggest_float(model_type + \"__reg_lambda\", 0, 10, step=0.1),\n",
    "            random_state=random_state,\n",
    "            n_jobs=n_cores\n",
    "        )))\n",
    "    elif model_type == 'KNN':\n",
    "        steps.append((\"model\",  KNeighborsRegressor(\n",
    "            n_neighbors=trial.suggest_int(model_type + \"__n_neighbors\", 15, 25, step=1), \n",
    "            weights=trial.suggest_categorical(model_type + \"__weights\", ['uniform', 'distance']),\n",
    "            metric=trial.suggest_categorical(model_type + \"__metric\", ['minkowski', 'l1', 'l2', 'cosine']),\n",
    "            n_jobs = n_cores)))\n",
    "\n",
    "    # Create the pipeline\n",
    "    pipeline = Pipeline(steps)\n",
    "\n",
    "    # Evaluate with cross-validation\n",
    "    mse = -cross_val_score(pipeline, X, y, \n",
    "                           cv=inner_cv, \n",
    "                           scoring=\"neg_mean_squared_error\", \n",
    "                           n_jobs=inner_cv.n_splits).mean()\n",
    "\n",
    "    return mse\n",
    "\n",
    "\n",
    "def generate_best_pipeline(study):\n",
    "    best_params = study.best_params\n",
    "    steps = []\n",
    "    steps.append((\"feature_reduction\", FeatureSelector(method=\"top_n_cv\", n_features=best_params[\"FeatureSelector__n_features\"])))\n",
    "    steps.append((\"mean_centering\", MeanCenterer()))\n",
    "    \n",
    "    if model_type == 'SVR_linear':\n",
    "        steps.append((\"model\", SVR(\n",
    "            kernel='linear',\n",
    "            C=best_params[model_type + \"__C\"],\n",
    "            epsilon=best_params[model_type + '__epsilon']\n",
    "        )))\n",
    "    elif model_type == 'PLS':\n",
    "        steps.append(\n",
    "            (\"model\", PLSRegression_X(n_components=best_params[model_type + '__n_components'])), \n",
    "        )\n",
    "    elif model_type == 'Ridge':\n",
    "        steps.append(\n",
    "            ('model', Ridge(alpha=best_params[model_type + '__alpha'], \n",
    "                                             random_state=random_state))\n",
    "        )\n",
    "    elif model_type == 'Lasso':\n",
    "        steps.append(\n",
    "            ('model', Lasso(alpha=best_params[model_type + '__alpha'], \n",
    "                                             random_state=random_state))\n",
    "        )\n",
    "    elif model_type == 'ElasticNet':\n",
    "        steps.append(\n",
    "            ('model', ElasticNet(alpha=best_params[model_type + '__alpha'],\n",
    "                                 random_state=random_state, \n",
    "                                l1_ratio = best_params[model_type + '__l1_ratio']))\n",
    "        )\n",
    "    elif model_type == \"SVR_poly\":\n",
    "        steps.append((\"model\", SVR(\n",
    "            kernel='poly',\n",
    "            C=best_params[model_type + '__C'],\n",
    "            epsilon=best_params[model_type + '__epsilon'],\n",
    "            degree=best_params[model_type + '__degree'],\n",
    "            coef0=best_params[model_type + '__coef0'], \n",
    "            gamma=best_params[model_type + '__gamma']\n",
    "        )))\n",
    "    elif model_type == \"SVR_rbf\":\n",
    "        steps.append((\"model\", SVR(\n",
    "            kernel='rbf',\n",
    "            C=best_params[model_type + '__C'],\n",
    "            epsilon=best_params[model_type + '__epsilon'],\n",
    "            gamma=best_params[model_type + '__gamma']\n",
    "        )))\n",
    "    elif model_type == \"RFR\":\n",
    "        steps.append((\"model\", RandomForestRegressor(\n",
    "            n_estimators=best_params[model_type + '__n_estimators'],\n",
    "            max_features=best_params[model_type + '__max_features'],\n",
    "            max_samples=best_params[model_type + '__max_samples'],\n",
    "            max_depth=best_params[model_type + '__max_depth'],\n",
    "            random_state=random_state,\n",
    "            n_jobs=int(n_cores/inner_cv.n_splits)\n",
    "        )))\n",
    "    elif model_type == \"XGBoost\":\n",
    "        steps.append((\"model\", XGB.XGBRegressor(\n",
    "            n_estimators=best_params[model_type + '__n_estimators'],\n",
    "            max_depth=best_params[model_type + '__n_estimators'],\n",
    "            learning_rate=best_params[model_type + '__learning_rate'],\n",
    "            subsample=best_params[model_type + '__subsample'],\n",
    "            reg_alpha=best_params[model_type + '__reg_alpha'],\n",
    "            reg_lambda=best_params[model_type + '__reg_lambda'],\n",
    "            random_state=random_state,\n",
    "            n_jobs=int(n_cores/inner_cv.n_splits)\n",
    "        )))\n",
    "    elif model_type == 'KNN':\n",
    "        steps.append((\"model\",  KNeighborsRegressor(\n",
    "            n_neighbors=best_params[model_type + '__n_neighbors'], \n",
    "            weights=best_params[model_type + '__weights'],\n",
    "            metric=best_params[model_type + '__metric'],\n",
    "            n_jobs = int(n_cores/inner_cv.n_splits))))\n",
    "\n",
    "    best_pipeline = Pipeline(steps)\n",
    "    return best_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cc8b99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(os.path.join(data_path, 'processed',  'expr_protein.csv'), index_col = 0).values\n",
    "y = pd.read_csv(os.path.join(data_path, 'processed', 'metastatic_potential_protein.csv'), index_col = 0)['mean'].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b25b8372",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_folds=10\n",
    "inner_folds=5\n",
    "n_trials = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "859f64b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nobackup/users/hmbaghda/Software/miniforge3/envs/metastatic_potential/lib/python3.13/site-packages/optuna/_experimental.py:31: ExperimentalWarning: Argument ``restart_strategy`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cmaes_sampler = CmaEsSampler(seed=random_state, \n",
    "                             warn_independent_sampling=False, \n",
    "                            restart_strategy='bipop')\n",
    "\n",
    "exploration_sampler = RandomSampler(seed=random_state)\n",
    "tpe_sampler = RandomTPESampler(seed=random_state, \n",
    "                               n_startup_trials = 15,\n",
    "                               exploration_sampler = exploration_sampler, \n",
    "                               exploration_freq=20 # randomly sample every n trials\n",
    "                              )\n",
    "# tpe_sampler = TPESampler(seed=random_state, \n",
    "#                         n_startup_trials = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9cff09ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_cv = KFold(n_splits=outer_folds, shuffle=True, random_state=random_state)\n",
    "inner_cv = KFold(n_splits=inner_folds, shuffle=True, random_state=random_state)\n",
    "\n",
    "if os.path.isfile(os.path.join(data_path, 'interim', 'pipeline_model_selection_proteomics_individual.csv')):\n",
    "    res_df = pd.read_csv(os.path.join(data_path, 'interim', 'pipeline_model_selection_proteomics_individual.csv'), \n",
    "                     index_col = 0)\n",
    "    results = res_df.to_dict(orient='records')\n",
    "else:\n",
    "    results = []\n",
    "    res_df = None\n",
    "\n",
    "for model_type in ['SVR_linear', 'PLS', 'Ridge', 'Lasso', 'ElasticNet', \n",
    "                   'SVR_poly', 'SVR_rbf', 'RFR', 'KNN']:#'XGBoost', ]:\n",
    "    for k, (train_idx, test_idx) in enumerate(outer_cv.split(X, y)):\n",
    "        if res_df is not None and res_df[(res_df.fold == k) & (res_df.model_type == model_type)].shape[0] != 0:\n",
    "            pass\n",
    "        else:\n",
    "            print(model_type + ': ' + str(k))\n",
    "            X_train, X_test = X[train_idx], X[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "\n",
    "            pruner = optuna.pruners.SuccessiveHalvingPruner()\n",
    "            study = optuna.create_study(direction=\"minimize\", \n",
    "                                        sampler=HybridSampler(primary_sampler=cmaes_sampler, fallback_sampler=tpe_sampler), \n",
    "                                       pruner = pruner, \n",
    "                                       study_name = '{}_optuna'.format(k))\n",
    "            study.optimize(\n",
    "                lambda trial: optuna_objective(trial, X_train, y_train, inner_cv, n_cores, random_state, model_type),\n",
    "                n_trials=n_trials, \n",
    "                catch=(ValueError,)\n",
    "            )\n",
    "    #         write_pickled_object(study, os.path.join(data_path, 'interim', study.study_name + '.pickle'))\n",
    "\n",
    "            best_pipeline = generate_best_pipeline(study)\n",
    "            best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "            y_train_pred = best_pipeline.predict(X_train)\n",
    "            y_test_pred = best_pipeline.predict(X_test)\n",
    "\n",
    "            train_corr = pearsonr(y_train, y_train_pred)[0]\n",
    "            test_corr = pearsonr(y_test, y_test_pred)[0]\n",
    "            train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "            test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "            results.append({\n",
    "                \"model_type\": model_type,\n",
    "                \"fold\": k,\n",
    "                \"train_corr\": train_corr,\n",
    "                \"test_corr\": test_corr,\n",
    "                \"train_mse\": train_mse,\n",
    "                \"test_mse\": test_mse,\n",
    "                \"best_params\": study.best_params,\n",
    "                \"inner_cv\": study.trials_dataframe()\n",
    "                })\n",
    "            res_df = pd.DataFrame(results)\n",
    "            res_df.to_csv(os.path.join(data_path, 'interim', 'pipeline_model_selection_proteomics_individual.csv'))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metastatic_potential]",
   "language": "python",
   "name": "conda-env-metastatic_potential-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
