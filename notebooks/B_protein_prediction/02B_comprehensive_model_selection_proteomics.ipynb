{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcb1ad68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nobackup/users/hmbaghda/Software/miniforge3/envs/metastatic_potential/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pathlib\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import CmaEsSampler, TPESampler, RandomSampler\n",
    "from optuna.distributions import CategoricalDistribution\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.linear_model import ElasticNet, Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "from utils import write_pickled_object\n",
    "from utils import FeatureSelector, MeanCenterer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c0dd2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/nobackup/users/hmbaghda/metastatic_potential/'\n",
    "random_state = 42 + 2\n",
    "\n",
    "n_cores = 80\n",
    "os.environ[\"OMP_NUM_THREADS\"] = str(n_cores)\n",
    "os.environ[\"MKL_NUM_THREADS\"] = str(n_cores)\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = str(n_cores)\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = str(n_cores)\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = str(n_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6133b0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_corr_scorer(y_true, y_pred):\n",
    "    return pearsonr(y_true, y_pred)[0]\n",
    "\n",
    "class PLSRegression_X(PLSRegression):\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = super().transform(X, y)\n",
    "        if isinstance(X_transformed, tuple):\n",
    "            X_transformed = X_transformed[0]\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d627a1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridSampler(optuna.samplers.BaseSampler):\n",
    "    def __init__(self, primary_sampler, fallback_sampler):\n",
    "        self.primary_sampler = primary_sampler  # e.g., CmaEsSampler\n",
    "        self.fallback_sampler = fallback_sampler  # e.g., TPESampler\n",
    "\n",
    "    def infer_relative_search_space(self, study, trial):\n",
    "        # Let the primary sampler define the relative search space\n",
    "        return self.primary_sampler.infer_relative_search_space(study, trial)\n",
    "\n",
    "    def sample_relative(self, study, trial, search_space):\n",
    "        # Let the primary sampler handle relative sampling\n",
    "        return self.primary_sampler.sample_relative(study, trial, search_space)\n",
    "\n",
    "    def sample_independent(self, study, trial, param_name, param_distribution):\n",
    "        # Use the fallback sampler for unsupported parameter types\n",
    "        if isinstance(param_distribution, CategoricalDistribution):\n",
    "            return self.fallback_sampler.sample_independent(study, trial, param_name, param_distribution)\n",
    "        # Default to the primary sampler\n",
    "        return self.primary_sampler.sample_independent(study, trial, param_name, param_distribution)\n",
    "\n",
    "class RandomTPESampler(TPESampler):\n",
    "    def __init__(self, exploration_sampler, exploration_freq=20, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.exploration_sampler = exploration_sampler\n",
    "        self.exploration_freq = exploration_freq\n",
    "\n",
    "    def sample_independent(self, study, trial, param_name, param_distribution):\n",
    "        # Use the exploration_sampler periodically\n",
    "        if trial.number % self.exploration_freq == 0:\n",
    "            return self.exploration_sampler.sample_independent(study, trial, param_name, param_distribution)\n",
    "        # Default to TPE\n",
    "        return super().sample_independent(study, trial, param_name, param_distribution)\n",
    "\n",
    "\n",
    "def optuna_objective(trial, X, y, inner_cv, n_cores, random_state):\n",
    "    # Define feature reduction/selection method\n",
    "        \n",
    "    steps = [\n",
    "        (\"feature_reduction\", FeatureSelector(method=\"top_n_cv\", \n",
    "                                              n_features=trial.suggest_categorical(\"FeatureSelector__n_features\", [250, 500, 1000, 5000, 12755]))),\n",
    "        (\"mean_centering\", MeanCenterer()),\n",
    "    ]\n",
    "\n",
    "\n",
    "    # Define model\n",
    "    model_type = trial.suggest_categorical(\"model_type\", [\"SVR\", 'PLS', 'Ridge'])\n",
    "    if model_type == \"SVR\":\n",
    "        steps.append((\"model\", SVR(\n",
    "            kernel='linear',\n",
    "            C=trial.suggest_float(\"SVR__C\", 1e-4, 1e2, log = True),\n",
    "            epsilon=trial.suggest_float(\"SVR__epsilon\", 1e-3, 10, log=True)\n",
    "        )))\n",
    "#     elif model_type == \"RFR\":\n",
    "#         steps.append((\"model\", RandomForestRegressor(\n",
    "#             n_estimators=trial.suggest_int(\"RFR__n_estimators\", 300, 1600, step=400),\n",
    "#             max_features=trial.suggest_categorical(\"RFR__max_features\", [\"sqrt\", \"log2\", 0.5, 0.75, 1]),\n",
    "#             max_samples=trial.suggest_categorical(\"RFR__max_samples\", [0.25, 0.5, 0.75, None]),\n",
    "#             max_depth=trial.suggest_categorical(\"RFR__max_depth\", [None, 10, 25, 50, 100, 200]),\n",
    "#             random_state=random_state,\n",
    "#             n_jobs=int(n_cores/inner_cv.n_splits)\n",
    "#         )))\n",
    "    elif model_type == 'PLS':\n",
    "        steps.append(\n",
    "            (\"model\", PLSRegression_X(n_components=trial.suggest_int(\"PLS__n_components\", 2, 100, step = 3))), \n",
    "        )\n",
    "    elif model_type == 'Ridge':\n",
    "        steps.append(\n",
    "            ('model', Ridge(alpha=trial.suggest_float(\"Ridge__alpha\", 1, 250, step = 10), \n",
    "                                             random_state=random_state))\n",
    "        )\n",
    "\n",
    "    # Create the pipeline\n",
    "    pipeline = Pipeline(steps)\n",
    "\n",
    "    # Evaluate with cross-validation\n",
    "    mse = -cross_val_score(pipeline, X, y, \n",
    "                           cv=inner_cv, \n",
    "                           scoring=\"neg_mean_squared_error\", \n",
    "                           n_jobs=inner_cv.n_splits).mean()\n",
    "\n",
    "#     for fold_idx, (train_idx, val_idx) in enumerate(inner_cv.split(X, y)):\n",
    "#         X_train, X_val = X[train_idx], X[val_idx]\n",
    "#         y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "#         # Train and evaluate the pipeline on the current fold\n",
    "#         pipeline.fit(X_train, y_train)\n",
    "#         y_val_pred = pipeline.predict(X_val)\n",
    "#         mse = mean_squared_error(y_val, y_val_pred)\n",
    "\n",
    "#         # Store the MSE for this fold\n",
    "#         mse_scores.append(mse)\n",
    "\n",
    "#         # Report intermediate result to Optuna\n",
    "#         trial.report(np.mean(mse_scores), step=fold_idx)\n",
    "\n",
    "#         # Check if the trial should be pruned\n",
    "#         if trial.should_prune():\n",
    "#             raise optuna.exceptions.TrialPruned()\n",
    "    \n",
    "#     return np.mean(mse_scores)\n",
    "\n",
    "    return mse\n",
    "\n",
    "\n",
    "def generate_best_pipeline(study):\n",
    "    best_params = study.best_params\n",
    "    steps = []\n",
    "    steps.append((\"feature_reduction\", FeatureSelector(method=\"top_n_cv\", n_features=best_params[\"FeatureSelector__n_features\"])))\n",
    "    steps.append((\"mean_centering\", MeanCenterer()))\n",
    "    \n",
    "    if \"SVR__C\" in best_params:\n",
    "        steps.append((\"model\", SVR(\n",
    "            kernel='linear',\n",
    "            C=best_params[\"SVR__C\"],\n",
    "            epsilon=best_params['SVR__epsilon']\n",
    "        )))\n",
    "#     elif \"RFR__n_estimators\" in best_params:\n",
    "#         steps.append((\"model\", RandomForestRegressor(\n",
    "#             n_estimators=best_params[\"RFR__n_estimators\"],\n",
    "#             max_features=best_params[\"RFR__max_features\"],\n",
    "#             max_samples=best_params[\"RFR__max_samples\"],\n",
    "#             max_depth=best_params[\"RFR__max_depth\"],\n",
    "#             random_state=random_state,\n",
    "#             n_jobs=n_cores\n",
    "#         )))\n",
    "    elif 'PLS__n_components' in best_params:\n",
    "        steps.append((\"model\", PLSRegression_X(n_components=best_params[\"PLS__n_components\"])))\n",
    "    elif 'Ridge__alpha' in best_params:\n",
    "        steps.append((\"model\", Ridge(alpha=best_params[\"Ridge__alpha\"], \n",
    "                                                      random_state=random_state)))\n",
    "\n",
    "    best_pipeline = Pipeline(steps)\n",
    "    return best_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0b152e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(os.path.join(data_path, 'processed',  'expr_protein.csv'), index_col = 0).values\n",
    "y = pd.read_csv(os.path.join(data_path, 'processed', 'metastatic_potential_protein.csv'), index_col = 0)['mean'].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23e5c234",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_folds=10\n",
    "inner_folds=5\n",
    "n_trials = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5344f6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nobackup/users/hmbaghda/Software/miniforge3/envs/metastatic_potential/lib/python3.13/site-packages/optuna/_experimental.py:31: ExperimentalWarning: Argument ``restart_strategy`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cmaes_sampler = CmaEsSampler(seed=random_state, \n",
    "                             warn_independent_sampling=False, \n",
    "                            restart_strategy='bipop')\n",
    "\n",
    "exploration_sampler = RandomSampler(seed=random_state)\n",
    "tpe_sampler = RandomTPESampler(seed=random_state, \n",
    "                               n_startup_trials = 25,\n",
    "                               exploration_sampler = exploration_sampler, \n",
    "                               exploration_freq=20 # randomly sample every n trials\n",
    "                              )\n",
    "# tpe_sampler = TPESampler(seed=random_state, \n",
    "#                         n_startup_trials = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5636eb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_cv = KFold(n_splits=outer_folds, shuffle=True, random_state=random_state)\n",
    "inner_cv = KFold(n_splits=inner_folds, shuffle=True, random_state=random_state)\n",
    "\n",
    "if os.path.isfile(os.path.join(data_path, 'interim', 'pipeline_model_selection_protein.csv')):\n",
    "    res_df = pd.read_csv(os.path.join(data_path, 'interim', 'pipeline_model_selection_protein.csv'), \n",
    "                     index_col = 0)\n",
    "    results = res_df.to_dict(orient='records')\n",
    "else:\n",
    "    results = []\n",
    "    res_df = None\n",
    "    \n",
    "for k, (train_idx, test_idx) in enumerate(outer_cv.split(X, y)):\n",
    "    if res_df is not None and res_df[res_df.fold == k].shape[0] != 0:\n",
    "        pass\n",
    "    else:\n",
    "        print(str(k))\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "\n",
    "        pruner = optuna.pruners.SuccessiveHalvingPruner()\n",
    "        study = optuna.create_study(direction=\"minimize\", \n",
    "                                    sampler=HybridSampler(primary_sampler=cmaes_sampler, fallback_sampler=tpe_sampler), \n",
    "                                   pruner = pruner, \n",
    "                                   study_name = '{}_optuna'.format(k))\n",
    "        study.optimize(\n",
    "            lambda trial: optuna_objective(trial, X_train, y_train, inner_cv, n_cores, random_state),\n",
    "            n_trials=n_trials, \n",
    "            catch=(ValueError,)\n",
    "        )\n",
    "        write_pickled_object(study, os.path.join(data_path, 'interim', study.study_name + '.pickle'))\n",
    "\n",
    "        best_pipeline = generate_best_pipeline(study)\n",
    "        best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = best_pipeline.predict(X_train)\n",
    "        y_test_pred = best_pipeline.predict(X_test)\n",
    "\n",
    "        train_corr = pearsonr(y_train, y_train_pred)[0]\n",
    "        test_corr = pearsonr(y_test, y_test_pred)[0]\n",
    "\n",
    "        results.append({\n",
    "            \"fold\": k,\n",
    "            \"train_corr\": train_corr,\n",
    "            \"test_corr\": test_corr,\n",
    "            \"best_params\": study.best_params,\n",
    "            \"inner_cv\": study.trials_dataframe()\n",
    "            })\n",
    "        res_df = pd.DataFrame(results)\n",
    "        res_df.to_csv(os.path.join(data_path, 'interim', 'pipeline_model_selection_protein.csv'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metastatic_potential]",
   "language": "python",
   "name": "conda-env-metastatic_potential-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
