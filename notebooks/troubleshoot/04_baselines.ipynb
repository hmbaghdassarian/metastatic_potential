{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6d06b519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from tqdm import tqdm \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "import scipy.stats as stats\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "92e1eda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "n_cores = 20\n",
    "data_path = '/nobackup/users/hmbaghda/metastatic_potential/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "fccd25a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val = pd.read_csv(os.path.join(data_path, 'interim', 'X_train_val.csv'), index_col = 0)\n",
    "y_train_val = pd.read_csv(os.path.join(data_path, 'interim', 'y_train_val.csv'), index_col = 0)\n",
    "\n",
    "X_test = pd.read_csv(os.path.join(data_path, 'interim', 'X_test.csv'), index_col = 0)\n",
    "y_test = pd.read_csv(os.path.join(data_path, 'interim', 'y_test.csv'), index_col = 0)\n",
    "y_test = y_test.values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a5e67d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_features = pd.read_csv(os.path.join(data_path, 'interim', 'depr_selected_features.csv'), index_col = 0)\n",
    "selected_features = pd.read_csv(os.path.join(data_path, 'interim', 'depr_selected_all_features.csv'), index_col = 0)\n",
    "\n",
    "selected_feature_index = selected_features.index.tolist()\n",
    "# selected_feature_index = open(os.path.join(data_path, 'interim', 'depre_selected_train.txt')).read().splitlines()\n",
    "\n",
    "selected_feature_index = ['-'.join(i.split('.')) for i in selected_feature_index] # formatting R --> python\n",
    "X_train_val.columns = ['-'.join(col.split('.')) for col in X_train_val.columns]\n",
    "X_test.columns = ['-'.join(col.split('.')) for col in X_test.columns]\n",
    "\n",
    "X_train_val = X_train_val.loc[:, selected_feature_index]\n",
    "X_test = X_test.loc[:, selected_feature_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0797842f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_ = res.infer_objects(copy = False).fillna('None')\n",
    "# hyperparam_names = ['n_estimators', 'max_features', 'max_samples', 'max_depth', 'min_samples_split', 'min_samples_leaf']\n",
    "# best_mse_params = list(res_.groupby(hyperparam_names)['mse'].mean().idxmin())\n",
    "# best_mse_params = [x if x != 'None' else None for x in best_mse_params]\n",
    "# best_mse_params = dict(zip(hyperparam_names, best_mse_params))\n",
    "\n",
    "# for hp in ['max_features', 'max_depth']:\n",
    "#     best_mse_params[hp] = int(best_mse_params[hp])\n",
    "\n",
    "# best_mse_params\n",
    "\n",
    "best_mse_params = {'n_estimators': np.int64(850),\n",
    " 'max_features': 1,\n",
    " 'max_samples': None,\n",
    " 'max_depth': 25,\n",
    " 'min_samples_split': np.int64(2),\n",
    " 'min_samples_leaf': np.int64(1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "540d2794",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:17,  1.79s/it]\n"
     ]
    }
   ],
   "source": [
    "rf_mse = []\n",
    "rf_pearson = []\n",
    "rf_spearman = []\n",
    "\n",
    "n_splits = 10\n",
    "kf = KFold(n_splits=n_splits, shuffle = True, random_state = seed)\n",
    "\n",
    "for i, (train_index, val_index) in tqdm(enumerate(kf.split(X_train_val, y_train_val))): # iterate through folds for train-val split and do the below loop for each fold\n",
    "\n",
    "    X_train, _ = X_train_val.iloc[train_index], X_train_val.iloc[val_index]\n",
    "    y_train, _ = y_train_val.iloc[train_index], y_train_val.iloc[val_index]\n",
    "    y_train = y_train.values.flatten()\n",
    "\n",
    "    # ACTUAL MODEL\n",
    "    model = RandomForestRegressor(n_estimators = best_mse_params['n_estimators'],\n",
    "                                  max_features = best_mse_params['max_features'],\n",
    "                                  max_samples = best_mse_params['max_samples'],\n",
    "                                  max_depth = best_mse_params['max_depth'],\n",
    "                                  min_samples_split = best_mse_params['min_samples_split'],\n",
    "                                  min_samples_leaf = best_mse_params['min_samples_leaf'],\n",
    "                                  n_jobs = n_cores,\n",
    "                                  random_state = seed)\n",
    "    # # training on shuffled features (random baseline)\n",
    "    # y_train_shuffled = y_train.values.reshape(-1).copy()\n",
    "    # np.random.shuffle(y_train_shuffled)\n",
    "    model.fit(X_train, y_train) # fit on the shuffled data\n",
    "\n",
    "    # predict on non-shuffled features\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # store results\n",
    "    rf_mse.append(mean_squared_error(y_test, y_pred))\n",
    "    rf_pearson.append(pearsonr(y_test, y_pred))\n",
    "    rf_spearman.append(stats.spearmanr(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b07c4d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7729713667799448)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([p.statistic for p in rf_pearson])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d377516f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8484809597786744)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([p.statistic for p in rf_pearson])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "039a3bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9094110559748193)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([p.statistic for p in rf_pearson])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "80358517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8503713784502173)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([p.statistic for p in rf_pearson])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b6c7fb03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.19661007752517684)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([p.statistic for p in rf_pearson])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54340d3d",
   "metadata": {},
   "source": [
    "validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "699a5a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:05,  1.89it/s]\n"
     ]
    }
   ],
   "source": [
    "rf_mse = []\n",
    "rf_pearson = []\n",
    "rf_spearman = []\n",
    "\n",
    "n_splits = 10\n",
    "kf = KFold(n_splits=n_splits, shuffle = True, random_state = seed)\n",
    "\n",
    "for i, (train_index, val_index) in tqdm(enumerate(kf.split(X_train_val, y_train_val))): # iterate through folds for train-val split and do the below loop for each fold\n",
    "\n",
    "    X_train, X_val = X_train_val.iloc[train_index], X_train_val.iloc[val_index]\n",
    "    y_train, y_val = y_train_val.iloc[train_index], y_train_val.iloc[val_index]\n",
    "    y_train = y_train.values.flatten()\n",
    "    y_val = y_val.values.flatten()\n",
    "\n",
    "    # ACTUAL MODEL\n",
    "#     model = RandomForestRegressor(n_estimators = best_mse_params['n_estimators'],\n",
    "#                                   max_features = best_mse_params['max_features'],\n",
    "#                                   max_samples = best_mse_params['max_samples'],\n",
    "#                                   max_depth = best_mse_params['max_depth'],\n",
    "#                                   min_samples_split = best_mse_params['min_samples_split'],\n",
    "#                                   min_samples_leaf = best_mse_params['min_samples_leaf'],\n",
    "#                                   n_jobs = n_cores,\n",
    "#                                   random_state = seed)\n",
    "    \n",
    "    model = RandomForestRegressor(n_jobs = n_cores,\n",
    "                                  random_state = seed)\n",
    "    # # training on shuffled features (random baseline)\n",
    "    # y_train_shuffled = y_train.values.reshape(-1).copy()\n",
    "    # np.random.shuffle(y_train_shuffled)\n",
    "    model.fit(X_train, y_train) # fit on the shuffled data\n",
    "\n",
    "    # predict on non-shuffled features\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    # store results\n",
    "    rf_mse.append(mean_squared_error(y_val, y_pred))\n",
    "    rf_pearson.append(pearsonr(y_val, y_pred))\n",
    "    rf_spearman.append(stats.spearmanr(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6cca68ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.5809239286874526)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([p.statistic for p in rf_pearson])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2c956f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6032467406260676)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([p.statistic for p in rf_pearson])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1899d74c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6343411831398538)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([p.statistic for p in rf_pearson])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1988a41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metastatic_potential]",
   "language": "python",
   "name": "conda-env-metastatic_potential-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
