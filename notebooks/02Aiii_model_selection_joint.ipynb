{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c73a212c",
   "metadata": {},
   "source": [
    "We run the data on many different models to get a set of candidate models that have high performance. We do some grid search to ensure that poor performance isn't due to hyperparameter constraints, however the complete hyperparameter tuning is implemented in Notebook 02B. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b0d1ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "import argparse\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.linear_model import Lasso,Ridge,ElasticNet\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor as KNN\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as XGB\n",
    "\n",
    "import plotnine as p9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63de970",
   "metadata": {},
   "source": [
    "Specify parameters and inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aeca60ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/nobackup/users/hmbaghda/metastatic_potential/'\n",
    "res_dir = os.path.join(data_path, 'interim')\n",
    "\n",
    "X_path = os.path.join(data_path, 'processed',  'expr_joint.csv')\n",
    "Y_path = os.path.join(data_path, 'processed', 'metastatic_potential_joint.csv')\n",
    "\n",
    "seed = 42\n",
    "\n",
    "num_folds = 10\n",
    "grid_search = True\n",
    "cv_folds = 5\n",
    "n_cores = 80\n",
    "\n",
    "model_types = ['PLSR','elasticNet', 'svm', \n",
    "               'rf', 'xgboost', 'knn']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aedabac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OMP_NUM_THREADS\"] = str(n_cores)\n",
    "os.environ[\"MKL_NUM_THREADS\"] = str(n_cores)\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = str(n_cores)\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = str(n_cores)\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = str(n_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03ba5e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(X_path,index_col=0)\n",
    "Y = pd.DataFrame(pd.read_csv(Y_path,index_col=0)['mean'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "830f1a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separately mean center protein/rna\n",
    "\n",
    "X_protein = X[[col for col in X.columns if col.startswith('sp')]]\n",
    "X_rna = X[[col for col in X.columns if not col.startswith('sp')]]\n",
    "X_protein = X_protein.subtract(X_protein.mean(axis=0), axis=1)\n",
    "X_rna = X_rna.subtract(X_rna.mean(axis=0), axis=1)\n",
    "\n",
    "X = pd.concat([X_protein, X_rna], axis = 1, ignore_index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8becc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_r(y_true, y_pred):\n",
    "    x = y_true\n",
    "    y = y_pred\n",
    "    mx = torch.mean(x, dim=0)\n",
    "    my = torch.mean(y, dim=0)\n",
    "    xm, ym = x - mx, y - my\n",
    "    r_num = torch.sum(xm * ym,dim=0)\n",
    "    x_square_sum = torch.sum(xm * xm,dim=0)\n",
    "    y_square_sum = torch.sum(ym * ym,dim=0)\n",
    "    r_den = torch.sqrt(x_square_sum * y_square_sum)\n",
    "    r = r_num / r_den\n",
    "    return r #torch.mean(r)\n",
    "\n",
    "def pair_pearsonr(x, y, axis=0):\n",
    "    mx = np.mean(x, axis=axis, keepdims=True)\n",
    "    my = np.mean(y, axis=axis, keepdims=True)\n",
    "    xm, ym = x-mx, y-my\n",
    "    r_num = np.add.reduce(xm * ym, axis=axis)\n",
    "    r_den = np.sqrt((xm*xm).sum(axis=axis) * (ym*ym).sum(axis=axis))\n",
    "    r = r_num / r_den\n",
    "    return r\n",
    "\n",
    "def getSamples(N, batchSize):\n",
    "    order = np.random.permutation(N)\n",
    "    outList = []\n",
    "    while len(order)>0:\n",
    "        outList.append(order[0:batchSize])\n",
    "        order = order[batchSize:]\n",
    "    return outList\n",
    "\n",
    "def L2Regularization(deepLearningModel, L2):\n",
    "    weightLoss = 0.\n",
    "    biasLoss = 0.\n",
    "    for layer in deepLearningModel:\n",
    "        if isinstance(layer, torch.nn.Linear):\n",
    "            weightLoss = weightLoss + L2 * torch.sum((layer.weight)**2)\n",
    "            biasLoss = biasLoss + L2 * torch.sum((layer.bias)**2)\n",
    "    L2Loss = biasLoss + weightLoss\n",
    "    return(L2Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "374f3ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = range(100, 1001, 250)\n",
    "svm_c = [10**i for i in range(-3, 3)]\n",
    "svm_gamma = [10**i for i in range(-3, 2)]\n",
    "# svm_epsilon = [10**i for i in range(-2, 1)]\n",
    "alpha = [10**i for i in range(-3, 3)]\n",
    "\n",
    "grid_search_params = {\n",
    "    'knn': {\n",
    "        'n_neighbors': range(5, 41, 5)\n",
    "    },\n",
    "    'plsr': {\n",
    "        'n_components': range(2, 16, 2)\n",
    "    }, \n",
    "    'rf': {\n",
    "        'n_estimators': n_estimators\n",
    "            },\n",
    "    'xgboost': {\n",
    "        'n_estimators': n_estimators\n",
    "    },\n",
    "    'svm': {\n",
    "        'kernel': ['linear', 'rbf', 'poly'],\n",
    "        'C': svm_c, \n",
    "        'gamma': svm_gamma,  # only poly and rbf\n",
    "        'degree': [2,3,4,5],  # only for poly\n",
    "#         'coef0':[0,0.1,0.5,1.,1.2,2.] # only for poly, \n",
    "        \n",
    "    },\n",
    "#     'svmRBF': {\n",
    "#         'C': svm_c,\n",
    "#         'gamma': svm_gamma,\n",
    "#         'epsilon': svm_epsilon\n",
    "#     }, \n",
    "#     'svmPoly':{\n",
    "#         'gamma': svm_gamma,\n",
    "#         'C': svm_c,\n",
    "#         'degree':[2,3,4,5],\n",
    "#         'coef0':[0,0.1,0.5,1.,1.2,2.]\n",
    "#     }, \n",
    "#     'lasso':{\n",
    "#         'alpha': alpha\n",
    "#     }, \n",
    "#     'ridge': {\n",
    "#         'alpha': alpha,\n",
    "#     }, \n",
    "    'elasticNet': {\n",
    "        'alpha': alpha,\n",
    "        'l1_ratio': np.arange(0, 1.01, 0.25) # with 0 and 1 inclusive, this also does ridge and lasso\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09587494",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "for mdl in model_types:\n",
    "    if mdl == 'knn':\n",
    "        if grid_search:\n",
    "            model = GridSearchCV(estimator=KNN(),\n",
    "                                 param_grid = grid_search_params['knn'], \n",
    "                                 cv=cv_folds, \n",
    "                                 n_jobs=cv_folds)\n",
    "        else:\n",
    "            model = KNN(n_neighbors=5) # default value\n",
    "    elif mdl=='PLSR':\n",
    "        if grid_search:\n",
    "            model = GridSearchCV(estimator=PLSRegression(scale=False),\n",
    "                                 param_grid = grid_search_params['plsr'], cv=cv_folds, n_jobs=cv_folds)\n",
    "        else:\n",
    "            model = PLSRegression(n_components=4,scale=False)\n",
    "    elif mdl == 'rf':\n",
    "        if grid_search:\n",
    "            model = GridSearchCV(estimator=RandomForestRegressor(n_jobs = int(n_cores/cv_folds)),\n",
    "                                 param_grid = grid_search_params['rf'], cv=cv_folds, n_jobs=cv_folds)\n",
    "        else:\n",
    "            model = RandomForestRegressor(n_estimators=800, n_jobs = int(n_cores/cv_folds))\n",
    "    elif mdl == 'xgboost':\n",
    "        if grid_search:\n",
    "            model = GridSearchCV(estimator=XGB.XGBRegressor(n_jobs = int(n_cores/cv_folds)),\n",
    "                                 param_grid = grid_search_params['xgboost'], cv=cv_folds, n_jobs=cv_folds)\n",
    "        else:\n",
    "            model = XGB.XGBRegressor(n_estimators=800, n_jobs = int(n_cores/cv_folds))\n",
    "    elif mdl == 'svm':\n",
    "        if grid_search:\n",
    "            model = GridSearchCV(estimator=SVR(),\n",
    "                                 param_grid = grid_search_params['svm'], cv=cv_folds, n_jobs=cv_folds)\n",
    "        else:\n",
    "            model = SVR(kernel='rbf')\n",
    "#     elif mdl == 'svmLinear':\n",
    "#         if grid_search:\n",
    "#             model = GridSearchCV(estimator=LinearSVR(),\n",
    "#                                  param_grid = grid_search_params['svmLinear'], cv=cv_folds, n_jobs=cv_folds)\n",
    "#         else:\n",
    "#             model = LinearSVR()\n",
    "#     elif mdl == 'svmRBF':\n",
    "#         if grid_search:\n",
    "#             model = GridSearchCV(estimator=SVR(kernel='rbf'),\n",
    "#                                  param_grid = grid_search_params['svmRBF'], \n",
    "#                                  cv=cv_folds, n_jobs=cv_folds)\n",
    "#         else:\n",
    "#             model = SVR(kernel='rbf')\n",
    "#     elif mdl == 'svmPoly':\n",
    "#         if grid_search:\n",
    "#             model = GridSearchCV(estimator=SVR(kernel='poly'),\n",
    "#                                  param_grid = grid_search_params['svmPoly'], \n",
    "#                                  cv=cv_folds, n_jobs=cv_folds)\n",
    "#         else:\n",
    "#             model = SVR(kernel='poly')\n",
    "#     elif mdl == 'lasso':\n",
    "#         if grid_search:\n",
    "#             model = GridSearchCV(estimator=Lasso(),\n",
    "#                                  param_grid = grid_search_params['lasso'], cv=cv_folds, n_jobs=cv_folds)\n",
    "#         else:\n",
    "#             model = Lasso(alpha=0.1)\n",
    "#     elif mdl == 'ridge':\n",
    "#         if grid_search:\n",
    "#             model = GridSearchCV(estimator=Ridge(),param_grid = grid_search_params['ridge'], \n",
    "#                                  cv=cv_folds, n_jobs=cv_folds)\n",
    "#         else:\n",
    "#             model = Ridge(alpha=0.1)\n",
    "    elif mdl == 'elasticNet':\n",
    "        if grid_search:\n",
    "            model = GridSearchCV(estimator=ElasticNet(),\n",
    "                                 param_grid = grid_search_params['elasticNet'], cv=cv_folds, n_jobs=cv_folds)\n",
    "        else:\n",
    "            model = ElasticNet(alpha=0.1)\n",
    "#     elif mdl == 'neuralNet':\n",
    "#         device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#         model = 'define the ANN just before it is trained'\n",
    "#         epochs = 100\n",
    "#         l2_reg  = 0.01\n",
    "#         bs = 20\n",
    "#         criterion = torch.nn.MSELoss(reduction='mean')\n",
    "#     models.append(model)\n",
    "    models[mdl] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9b14ea",
   "metadata": {},
   "source": [
    "Run the iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2619f2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                     | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begun fitting and evaluation for model: PLSR\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=num_folds,shuffle=True,random_state=seed)\n",
    "\n",
    "if os.path.isfile(os.path.join(data_path, 'processed', 'coarse_model_tests_joint.csv')):\n",
    "    res = pd.read_csv(os.path.join(data_path, 'processed', 'coarse_model_tests_joint.csv'), \n",
    "                     index_col = 0)\n",
    "else:\n",
    "    res = pd.DataFrame(columns = ['model_type', 'fold', 'train_pearson', 'test_pearson', 'best_params'])\n",
    "\n",
    "for model_type, model in tqdm(models.items()):\n",
    "    print('Begun fitting and evaluation for model: %s'%model_type)\n",
    "    for k, (train_index, test_index) in enumerate(cv.split(X)):\n",
    "        if res[(res.model_type == model_type) & (res.fold == k)].shape[0] == 0:\n",
    "            x_train = X.iloc[train_index,:].values\n",
    "            x_test = X.iloc[test_index,:].values\n",
    "            y_train = Y.iloc[train_index,:].values.ravel()\n",
    "            y_test = Y.iloc[test_index,:].values.ravel()\n",
    "\n",
    "\n",
    "            # fit model and evaluate in validation set\n",
    "            model.fit(x_train,y_train)\n",
    "            yhat_train = model.predict(x_train)\n",
    "            yhat_test = model.predict(x_test)\n",
    "\n",
    "            train_pearson=pair_pearsonr(y_train, yhat_train, axis=0).mean()\n",
    "            test_pearson=pair_pearsonr(y_test, yhat_test, axis=0).mean()\n",
    "\n",
    "            res.loc[res.shape[0], :] = [model_type, k, train_pearson, test_pearson, model.best_params_]\n",
    "            res.to_csv(os.path.join(data_path, 'processed', 'coarse_model_tests_joint.csv'))\n",
    "        else:\n",
    "            pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b489c0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.read_csv(os.path.join(data_path, 'processed', 'coarse_model_tests.csv'), index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d787a0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_type\n",
       "elasticNet    0.490122\n",
       "svm           0.485983\n",
       "PLSR          0.458110\n",
       "rf            0.444133\n",
       "knn           0.411534\n",
       "xgboost       0.324319\n",
       "Name: test_pearson, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.groupby('model_type').test_pearson.mean().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652491ef",
   "metadata": {},
   "source": [
    "Since our 3rd best model is very similar in performance to our 4th best, we will now more comprehensively sweep all of these. We also see that \n",
    "- elasticNet consitenly chose a ridge penalty, so we use ridge rather than elasticNet.  \n",
    "- svm was always the linear kernel, so we proceed with that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metastatic_potential]",
   "language": "python",
   "name": "conda-env-metastatic_potential-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
