{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "00222835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "import argparse\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.linear_model import Lasso,Ridge,ElasticNet\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor as KNN\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as XGB\n",
    "\n",
    "import plotnine as p9\n",
    "from sklearn.decomposition import SparsePCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a939da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser(description='Run different ML models')\n",
    "# parser.add_argument('--model_types', metavar='N', type=str, nargs='*', help='models to train',default=['PLSR','knn' ,'svmLinear','svmRBF','svmPoly','lasso','ridge','elasticNet','neuralNet','xgboost','rf'])\n",
    "# parser.add_argument('--X_path', action='store', type=str,help='path to the input training data',default='X.csv')\n",
    "# parser.add_argument('--Y_path', action='store', type=str,help='path to the output training data',default='y.csv')\n",
    "# parser.add_argument('--num_folds', action='store', type=int,help='number of folds',default=10)\n",
    "# parser.add_argument('--res_dir', action='store', type=str,help='Results directory',default='/nobackup/users/hmbaghda/metastatic_potential/interim/')\n",
    "# parser.add_argument('--seed', action='store', type=int,help='seed',default=42)\n",
    "# parser.add_argument('--grid_search', action='store', type=bool,help='Nested Hyperparameter Tuning',default=True)\n",
    "# parser.add_argument('--hyperparam_folds', action='store', type=int,help='number of hyperparametr tuning folds',default=5)\n",
    "# parser.add_argument('--n_cores', action='store', type=int,help='number of cores for parallelization',default=20)\n",
    "\n",
    "# args = parser.parse_args()\n",
    "# model_types = args.model_types\n",
    "# num_folds = args.num_folds\n",
    "# X_path = args.X_path\n",
    "# Y_path = args.Y_path\n",
    "# res_dir= args.res_dir\n",
    "# seed = args.seed\n",
    "# cv_folds = args.hyperparam_folds\n",
    "\n",
    "# params\n",
    "data_path = '/nobackup/users/hmbaghda/metastatic_potential/'\n",
    "res_dir = os.path.join(data_path, 'interim')\n",
    "\n",
    "hvg_selection = False # whether to filter for HVGs\n",
    "hvg_name = '' if not hvg_selection else 'hvg_'\n",
    "X_path = os.path.join(data_path, 'processed',  hvg_name + 'expr.csv')\n",
    "Y_path = os.path.join(data_path, 'processed', 'metastatic_potential.csv')\n",
    "\n",
    "seed = 42\n",
    "\n",
    "num_folds = 10\n",
    "grid_search = True\n",
    "cv_folds = 5\n",
    "n_cores = 30\n",
    "\n",
    "model_types = ['PLSR','elasticNet', 'svm', \n",
    "               'rf', 'xgboost', 'knn']\n",
    "model_types = ['PLSR', 'ridge']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84a27b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OMP_NUM_THREADS\"] = str(n_cores)\n",
    "os.environ[\"MKL_NUM_THREADS\"] = str(n_cores)\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = str(n_cores)\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = str(n_cores)\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = str(n_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4247fb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(X_path,index_col=0).T\n",
    "Y = pd.read_csv(Y_path,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5372c1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_r(y_true, y_pred):\n",
    "    x = y_true\n",
    "    y = y_pred\n",
    "    mx = torch.mean(x, dim=0)\n",
    "    my = torch.mean(y, dim=0)\n",
    "    xm, ym = x - mx, y - my\n",
    "    r_num = torch.sum(xm * ym,dim=0)\n",
    "    x_square_sum = torch.sum(xm * xm,dim=0)\n",
    "    y_square_sum = torch.sum(ym * ym,dim=0)\n",
    "    r_den = torch.sqrt(x_square_sum * y_square_sum)\n",
    "    r = r_num / r_den\n",
    "    return r #torch.mean(r)\n",
    "\n",
    "def pair_pearsonr(x, y, axis=0):\n",
    "    mx = np.mean(x, axis=axis, keepdims=True)\n",
    "    my = np.mean(y, axis=axis, keepdims=True)\n",
    "    xm, ym = x-mx, y-my\n",
    "    r_num = np.add.reduce(xm * ym, axis=axis)\n",
    "    r_den = np.sqrt((xm*xm).sum(axis=axis) * (ym*ym).sum(axis=axis))\n",
    "    r = r_num / r_den\n",
    "    return r\n",
    "\n",
    "def getSamples(N, batchSize):\n",
    "    order = np.random.permutation(N)\n",
    "    outList = []\n",
    "    while len(order)>0:\n",
    "        outList.append(order[0:batchSize])\n",
    "        order = order[batchSize:]\n",
    "    return outList\n",
    "\n",
    "def L2Regularization(deepLearningModel, L2):\n",
    "    weightLoss = 0.\n",
    "    biasLoss = 0.\n",
    "    for layer in deepLearningModel:\n",
    "        if isinstance(layer, torch.nn.Linear):\n",
    "            weightLoss = weightLoss + L2 * torch.sum((layer.weight)**2)\n",
    "            biasLoss = biasLoss + L2 * torch.sum((layer.bias)**2)\n",
    "    L2Loss = biasLoss + weightLoss\n",
    "    return(L2Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b3db4594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3021289880432848\n",
      "0.31614282477540595\n",
      "0.5693814903942188\n",
      "0.24535389078449696\n",
      "0.5765393989242495\n",
      "0.14676192292619647\n",
      "0.36886484039028905\n",
      "0.2692737685030734\n",
      "0.5266563874662774\n",
      "0.27114892900524024\n"
     ]
    }
   ],
   "source": [
    "# initialize models\n",
    "# initialize models\n",
    "# nonlinear_params={\n",
    "#     'kernel': ['rbf', 'poly'],\n",
    "#     'C': [10**i for i in range(-3, 3)], \n",
    "#     'degree': [2,3,4,5],  # only for poly\n",
    "# }\n",
    "# nonlinear_model = GridSearchCV(estimator=SVR(gamma = 0.001, kernel = 'rbf'),\n",
    "#                          param_grid = nonlinear_params, \n",
    "#                          cv=cv_folds, \n",
    "#                          n_jobs=n_cores)\n",
    "nonlinear_params={'n_estimators': [100,200]}\n",
    "nonlinear_model = GridSearchCV(estimator=RandomForestRegressor(),\n",
    "                         param_grid = nonlinear_params, \n",
    "                         cv=cv_folds, \n",
    "                         n_jobs=n_cores)\n",
    "pls_model = PLSRegression(n_components=30,scale=False)\n",
    "\n",
    "res = pd.DataFrame(columns = ['fold', 'train_pearson', 'test_pearson', 'best_params'])\n",
    "cv = KFold(n_splits=num_folds,shuffle=True,random_state=seed)\n",
    "for k, (train_index, test_index) in enumerate(cv.split(X)):\n",
    "    x_train = X.iloc[train_index,:].values\n",
    "    x_test = X.iloc[test_index,:].values\n",
    "    y_train = Y.iloc[train_index,:].values.ravel()\n",
    "    y_test = Y.iloc[test_index,:].values.ravel()\n",
    "    \n",
    "    # get LVs from PLS\n",
    "    pls_model.fit(x_train, y_train)\n",
    "    pls_lvs_train = pls_model.x_scores_\n",
    "    \n",
    "    # hyperparameter tuning\n",
    "    nonlinear_model.fit(pls_lvs_train, y_train)\n",
    "    \n",
    "    # predict\n",
    "    pls_lvs_test = pls_model.transform(x_test)\n",
    "    yhat_train = nonlinear_model.predict(pls_lvs_train)\n",
    "    yhat_test = nonlinear_model.predict(pls_lvs_test)\n",
    "    \n",
    "    train_pearson=pair_pearsonr(y_train, yhat_train, axis=0).mean()\n",
    "    test_pearson=pair_pearsonr(y_test, yhat_test, axis=0).mean()\n",
    "    print(test_pearson)\n",
    "    \n",
    "    res.loc[res.shape[0], :] = [k, train_pearson, test_pearson, nonlinear_model.best_params_]\n",
    "#     res.to_csv(os.path.join(data_path, 'processed', 'plsr_svr.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1abc982",
   "metadata": {},
   "source": [
    "# Startm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "eb87f0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize models\n",
    "# initialize models\n",
    "# nonlinear_params={\n",
    "#     'kernel': ['rbf', 'poly'],\n",
    "#     'C': [10**i for i in range(-3, 3)], \n",
    "#     'degree': [2,3,4,5],  # only for poly\n",
    "# }\n",
    "# nonlinear_model = GridSearchCV(estimator=SVR(gamma = 0.001, kernel = 'rbf'),\n",
    "#                          param_grid = nonlinear_params, \n",
    "#                          cv=cv_folds, \n",
    "#                          n_jobs=n_cores)\n",
    "nonlinear_params={'n_estimators': [100,200]}\n",
    "nonlinear_model = GridSearchCV(estimator=RandomForestRegressor(),\n",
    "                         param_grid = nonlinear_params, \n",
    "                         cv=cv_folds, \n",
    "                         n_jobs=n_cores)\n",
    "linear_model = PCA(n_components=50, n_jobs = n_cores)\n",
    "\n",
    "\n",
    "res = pd.DataFrame(columns = ['fold', 'train_pearson', 'test_pearson', 'best_params'])\n",
    "cv = KFold(n_splits=num_folds,shuffle=True,random_state=seed)\n",
    "for k, (train_index, test_index) in enumerate(cv.split(X)):\n",
    "    x_train = X.iloc[train_index,:].values\n",
    "    x_test = X.iloc[test_index,:].values\n",
    "    y_train = Y.iloc[train_index,:].values.ravel()\n",
    "    y_test = Y.iloc[test_index,:].values.ravel()\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63fa85a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5bbf6694",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[146], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlinear_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nobackup/users/hmbaghda/Software/miniforge3/envs/metastatic_potential/lib/python3.13/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nobackup/users/hmbaghda/Software/miniforge3/envs/metastatic_potential/lib/python3.13/site-packages/sklearn/decomposition/_sparse_pca.py:91\u001b[0m, in \u001b[0;36m_BaseSparsePCA.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m     n_components \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components\n\u001b[0;32m---> 91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nobackup/users/hmbaghda/Software/miniforge3/envs/metastatic_potential/lib/python3.13/site-packages/sklearn/decomposition/_sparse_pca.py:313\u001b[0m, in \u001b[0;36mSparsePCA._fit\u001b[0;34m(self, X, n_components, random_state)\u001b[0m\n\u001b[1;32m    311\u001b[0m code_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mV_init\u001b[38;5;241m.\u001b[39mT \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mV_init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    312\u001b[0m dict_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mU_init\u001b[38;5;241m.\u001b[39mT \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mU_init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 313\u001b[0m code, dictionary, E, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43mdict_learning\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcode_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdict_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdict_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_n_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;66;03m# flip eigenvectors' sign to enforce deterministic output\u001b[39;00m\n\u001b[1;32m    328\u001b[0m code, dictionary \u001b[38;5;241m=\u001b[39m svd_flip(code, dictionary, u_based_decision\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/nobackup/users/hmbaghda/Software/miniforge3/envs/metastatic_potential/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m/nobackup/users/hmbaghda/Software/miniforge3/envs/metastatic_potential/lib/python3.13/site-packages/sklearn/decomposition/_dict_learning.py:1078\u001b[0m, in \u001b[0;36mdict_learning\u001b[0;34m(X, n_components, alpha, max_iter, tol, method, n_jobs, dict_init, code_init, callback, verbose, random_state, return_n_iter, positive_dict, positive_code, method_max_iter)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Solve a dictionary learning matrix factorization problem.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m \n\u001b[1;32m    931\u001b[0m \u001b[38;5;124;03mFinds the best dictionary and the corresponding sparse code for\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;124;03mnp.float64(0.01...)\u001b[39;00m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m estimator \u001b[38;5;241m=\u001b[39m DictionaryLearning(\n\u001b[1;32m   1063\u001b[0m     n_components\u001b[38;5;241m=\u001b[39mn_components,\n\u001b[1;32m   1064\u001b[0m     alpha\u001b[38;5;241m=\u001b[39malpha,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1076\u001b[0m     transform_max_iter\u001b[38;5;241m=\u001b[39mmethod_max_iter,\n\u001b[1;32m   1077\u001b[0m )\u001b[38;5;241m.\u001b[39mset_output(transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1078\u001b[0m code \u001b[38;5;241m=\u001b[39m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_n_iter:\n\u001b[1;32m   1080\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m   1081\u001b[0m         code,\n\u001b[1;32m   1082\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mcomponents_,\n\u001b[1;32m   1083\u001b[0m         estimator\u001b[38;5;241m.\u001b[39merror_,\n\u001b[1;32m   1084\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mn_iter_,\n\u001b[1;32m   1085\u001b[0m     )\n",
      "File \u001b[0;32m/nobackup/users/hmbaghda/Software/miniforge3/envs/metastatic_potential/lib/python3.13/site-packages/sklearn/utils/_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    322\u001b[0m         )\n",
      "File \u001b[0;32m/nobackup/users/hmbaghda/Software/miniforge3/envs/metastatic_potential/lib/python3.13/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nobackup/users/hmbaghda/Software/miniforge3/envs/metastatic_potential/lib/python3.13/site-packages/sklearn/decomposition/_dict_learning.py:1681\u001b[0m, in \u001b[0;36mDictionaryLearning.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1678\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1679\u001b[0m     n_components \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components\n\u001b[0;32m-> 1681\u001b[0m V, U, E, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43m_dict_learning\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1684\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod_max_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_max_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcode_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdict_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdict_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1694\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1695\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_n_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1696\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpositive_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpositive_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpositive_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpositive_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1698\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1699\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponents_ \u001b[38;5;241m=\u001b[39m U\n\u001b[1;32m   1700\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_ \u001b[38;5;241m=\u001b[39m E\n",
      "File \u001b[0;32m/nobackup/users/hmbaghda/Software/miniforge3/envs/metastatic_potential/lib/python3.13/site-packages/sklearn/decomposition/_dict_learning.py:620\u001b[0m, in \u001b[0;36m_dict_learning\u001b[0;34m(X, n_components, alpha, max_iter, tol, method, n_jobs, dict_init, code_init, callback, verbose, random_state, return_n_iter, positive_dict, positive_code, method_max_iter)\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    615\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIteration \u001b[39m\u001b[38;5;132;01m% 3i\u001b[39;00m\u001b[38;5;124m (elapsed time: \u001b[39m\u001b[38;5;132;01m% 3i\u001b[39;00m\u001b[38;5;124ms, \u001b[39m\u001b[38;5;132;01m% 4.1f\u001b[39;00m\u001b[38;5;124mmn, current cost \u001b[39m\u001b[38;5;132;01m% 7.3f\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    616\u001b[0m         \u001b[38;5;241m%\u001b[39m (ii, dt, dt \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m60\u001b[39m, current_cost)\n\u001b[1;32m    617\u001b[0m     )\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Update code\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m code \u001b[38;5;241m=\u001b[39m \u001b[43msparse_encode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdictionary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpositive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpositive_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod_max_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# Update dictionary in place\u001b[39;00m\n\u001b[1;32m    633\u001b[0m _update_dict(\n\u001b[1;32m    634\u001b[0m     dictionary,\n\u001b[1;32m    635\u001b[0m     X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    639\u001b[0m     positive\u001b[38;5;241m=\u001b[39mpositive_dict,\n\u001b[1;32m    640\u001b[0m )\n",
      "File \u001b[0;32m/nobackup/users/hmbaghda/Software/miniforge3/envs/metastatic_potential/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m/nobackup/users/hmbaghda/Software/miniforge3/envs/metastatic_potential/lib/python3.13/site-packages/sklearn/decomposition/_dict_learning.py:377\u001b[0m, in \u001b[0;36msparse_encode\u001b[0;34m(X, dictionary, gram, cov, algorithm, n_nonzero_coefs, alpha, copy_cov, init, max_iter, n_jobs, check_input, verbose, positive)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDictionary and X have different numbers of features:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdictionary.shape: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m X.shape\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(dictionary\u001b[38;5;241m.\u001b[39mshape, X\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    373\u001b[0m     )\n\u001b[1;32m    375\u001b[0m _check_positive_coding(algorithm, positive)\n\u001b[0;32m--> 377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_sparse_encode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdictionary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgram\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgram\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcov\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgorithm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_nonzero_coefs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_nonzero_coefs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy_cov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy_cov\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpositive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpositive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nobackup/users/hmbaghda/Software/miniforge3/envs/metastatic_potential/lib/python3.13/site-packages/sklearn/decomposition/_dict_learning.py:453\u001b[0m, in \u001b[0;36m_sparse_encode\u001b[0;34m(X, dictionary, gram, cov, algorithm, n_nonzero_coefs, alpha, copy_cov, init, max_iter, n_jobs, verbose, positive)\u001b[0m\n\u001b[1;32m    450\u001b[0m code \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((n_samples, n_components))\n\u001b[1;32m    451\u001b[0m slices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(gen_even_slices(n_samples, effective_n_jobs(n_jobs)))\n\u001b[0;32m--> 453\u001b[0m code_views \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_sparse_encode_precomputed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mthis_slice\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdictionary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgram\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgram\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcov\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis_slice\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcov\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgorithm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregularization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregularization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy_cov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy_cov\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m[\u001b[49m\u001b[43mthis_slice\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpositive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpositive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mthis_slice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mslices\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m this_slice, this_view \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(slices, code_views):\n\u001b[1;32m    470\u001b[0m     code[this_slice] \u001b[38;5;241m=\u001b[39m this_view\n",
      "File \u001b[0;32m/nobackup/users/hmbaghda/Software/miniforge3/envs/metastatic_potential/lib/python3.13/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nobackup/users/hmbaghda/Software/miniforge3/envs/metastatic_potential/lib/python3.13/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nobackup/users/hmbaghda/Software/miniforge3/envs/metastatic_potential/lib/python3.13/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/nobackup/users/hmbaghda/Software/miniforge3/envs/metastatic_potential/lib/python3.13/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "linear_model.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36af867",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca96c117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2cd8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get LVs from PLS\n",
    "pls_model.fit(x_train, y_train)\n",
    "pls_lvs_train = pls_model.x_scores_\n",
    "\n",
    "# hyperparameter tuning\n",
    "nonlinear_model.fit(pls_lvs_train, y_train)\n",
    "\n",
    "# predict\n",
    "pls_lvs_test = pls_model.transform(x_test)\n",
    "yhat_train = nonlinear_model.predict(pls_lvs_train)\n",
    "yhat_test = nonlinear_model.predict(pls_lvs_test)\n",
    "\n",
    "train_pearson=pair_pearsonr(y_train, yhat_train, axis=0).mean()\n",
    "test_pearson=pair_pearsonr(y_test, yhat_test, axis=0).mean()\n",
    "print(test_pearson)\n",
    "\n",
    "res.loc[res.shape[0], :] = [k, train_pearson, test_pearson, nonlinear_model.best_params_]\n",
    "#     res.to_csv(os.path.join(data_path, 'processed', 'plsr_svr.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metastatic_potential]",
   "language": "python",
   "name": "conda-env-metastatic_potential-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
