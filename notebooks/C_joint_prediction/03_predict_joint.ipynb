{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dcb1ad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pathlib\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c0dd2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/nobackup/users/hmbaghda/metastatic_potential/'\n",
    "random_state = 42 + 3\n",
    "\n",
    "n_cores = 30\n",
    "os.environ[\"OMP_NUM_THREADS\"] = str(n_cores)\n",
    "os.environ[\"MKL_NUM_THREADS\"] = str(n_cores)\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = str(n_cores)\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = str(n_cores)\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = str(n_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ccf071d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_pickled_object(object_, file_name: str) -> None:\n",
    "    if '.' in file_name:\n",
    "        p = pathlib.Path(file_name)\n",
    "        extensions = \"\".join(p.suffixes)\n",
    "        file_name = str(p).replace(extensions, '.pickle')\n",
    "    else:\n",
    "        file_name = file_name + '.pickle'\n",
    "\n",
    "    with open(file_name, 'wb') as handle:\n",
    "        pickle.dump(object_, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6133b0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection transformer\n",
    "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, method='top_n_cv', n_features=None):\n",
    "        if method not in ['top_n_cv']:#, 'all_features']:\n",
    "            raise ValueError('Incorrect feature selection method implemented')\n",
    "        self.method = method\n",
    "        self.n_features = n_features\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if self.method == 'top_n_cv':\n",
    "            self.coefficient_of_variation_ = np.std(X, axis=0) / np.mean(X, axis=0)\n",
    "            self.top_indices_ = np.argsort(self.coefficient_of_variation_)[::-1][:self.n_features]\n",
    "#         elif self.method == 'all_features':\n",
    "#             self.top_indices_ = range(X.shape[1])\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X[:, self.top_indices_]\n",
    "    \n",
    "class MeanCenterer(TransformerMixin, BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "#         self.mean_ = np.mean(X, axis=0)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X - np.mean(X, axis=0)\n",
    "    \n",
    "def pearson_corr_scorer(y_true, y_pred):\n",
    "    return pearsonr(y_true, y_pred)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0b152e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(os.path.join(data_path, 'processed',  'expr_joint.csv'), index_col = 0).values\n",
    "y = pd.read_csv(os.path.join(data_path, 'processed', 'metastatic_potential_joint.csv'), index_col = 0)['mean'].values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac92a03",
   "metadata": {},
   "source": [
    "Let's take a look at the results from the model selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e00769f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.read_csv(os.path.join(data_path, 'interim', 'pipeline_model_selection_joint.csv'), index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee329bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.test_corr.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfca240",
   "metadata": {},
   "source": [
    "Select a best consensus model and re-run on new folds to see the performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87ff1476",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_best = []\n",
    "epsilon_best = []\n",
    "for bp in res.best_params:\n",
    "    print(bp)\n",
    "    print('------------------------------------------------------')\n",
    "    C_best.append(float(bp.split(', ')[2].split(': ')[1]))\n",
    "    epsilon_best.append(float(bp.split(', ')[-1].split(': ')[1][:-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dd30e3",
   "metadata": {},
   "source": [
    "Looks like consistently, the best performing model uses all features and a linear SVM. We will take the median C and epsiolon value across folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12362acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_steps = [\n",
    "    (\"feature_reduction\", FeatureSelector(n_features = 19138)),\n",
    "    (\"mean_centering\", MeanCenterer()),\n",
    "]\n",
    "best_steps.append((\"model\", SVR(\n",
    "    kernel='linear',\n",
    "    C=np.median(C_best),\n",
    "    epsilon=np.median(epsilon_best)\n",
    "#     random_state=random_state,\n",
    "#     n_jobs=n_cores\n",
    ")))\n",
    "best_pipeline = Pipeline(best_steps)\n",
    "write_pickled_object(best_pipeline, \n",
    "                    os.path.join(data_path, 'processed', 'best_model.pickle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27c0006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(os.path.join(data_path, 'processed',  'expr.csv'), index_col = 0).values\n",
    "y = pd.read_csv(os.path.join(data_path, 'processed', 'metastatic_potential.csv'), index_col = 0)['mean'].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "498ca571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(X, y, n_synthetic, alpha=2, random_state=None):\n",
    "    \"\"\"\n",
    "    Create synthetic samples using the mixup technique.\n",
    "\n",
    "    Parameters:\n",
    "    - n_synthetic (int): Number of synthetic samples to generate.\n",
    "    - alpha (float): Parameter for the Beta distribution controlling the mixup ratio.\n",
    "    - random_seed (int, optional): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - synthetic_data (np.ndarray): A 2D array of shape (n_synthetic, features) with synthetic samples.\n",
    "    \"\"\"\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    n_samples, n_features = X.shape\n",
    "    synthetic_X = np.zeros((n_synthetic, n_features))\n",
    "    synthetic_y = np.zeros((n_synthetic, ))\n",
    "\n",
    "    for i in range(n_synthetic):\n",
    "        # Randomly select two samples to mix\n",
    "        idx1, idx2 = np.random.choice(n_samples, size=2, replace=False)\n",
    "        \n",
    "        # Generate mixup coefficient from a Beta distribution\n",
    "        lambda_ = np.random.beta(alpha, alpha)\n",
    "        \n",
    "        # Create a synthetic sample\n",
    "        synthetic_X[i] = lambda_ * X[idx1] + (1 - lambda_) * X[idx2]\n",
    "        synthetic_y[i] = lambda_ * y[idx1] + (1 - lambda_) * y[idx2]\n",
    "    \n",
    "    return synthetic_X, synthetic_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8f8e4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(model, y_train, y_test, X_train, X_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    train_corr = pearsonr(y_train, y_train_pred)[0]\n",
    "    test_corr = pearsonr(y_test, y_test_pred)[0]\n",
    "    \n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "    \n",
    "    return train_corr, test_corr, train_mse, test_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d82e3155",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:07, 12.76s/it]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(random_state + 1)\n",
    "outer_cv = KFold(n_splits=10, shuffle=True, random_state=random_state+1)\n",
    "n_synthetic = 1000\n",
    "augment = False\n",
    "# res = {}\n",
    "\n",
    "baseline_linear = LinearRegression(n_jobs = n_cores)\n",
    "\n",
    "results = []\n",
    "for k, (train_idx, test_idx) in tqdm(enumerate(outer_cv.split(X, y))):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    # augment data\n",
    "    if augment:\n",
    "        synthetic_X, synthetic_y = mixup(X_train, y_train, n_synthetic = n_synthetic, alpha = 2, random_state = random_state)\n",
    "        X_train = np.concatenate((X_train, synthetic_X), axis = 0)\n",
    "        y_train = np.concatenate((y_train, synthetic_y), axis = 0)\n",
    "\n",
    "    train_corr, test_corr, train_mse, test_mse = get_stats(best_pipeline, y_train, y_test, X_train, X_test)\n",
    "    \n",
    "    # random - y\n",
    "    y_train_rand = np.random.permutation(y_train)\n",
    "    res_y_rand = get_stats(best_pipeline, y_train_rand, y_test, X_train, X_test)\n",
    "    _, test_corr_y_rand, _, test_mse_y_rand = res_y_rand    \n",
    "    \n",
    "    # random - X (features)\n",
    "    X_train_rand = X_train[:, np.random.permutation(X_train.shape[1])]\n",
    "    res_X_rand = get_stats(best_pipeline, y_train, y_test, X_train_rand, X_test)\n",
    "    _, test_corr_X_rand, _, test_mse_X_rand = res_X_rand  \n",
    "    \n",
    "    # linear simple\n",
    "    linear_res = get_stats(baseline_linear, y_train, y_test, X_train, X_test)\n",
    "    _, test_corr_linear, _, test_mse_linear = linear_res\n",
    "    \n",
    "\n",
    "    results.append({\n",
    "        \"fold\": k,\n",
    "        \"train_corr\": train_corr,\n",
    "        \"test_corr\": test_corr,\n",
    "        'train_mse': train_mse, \n",
    "        'test_mse': test_mse,\n",
    "        'random_y_test_corr': test_corr_y_rand, \n",
    "        'random_y_test_mse': test_mse_y_rand, \n",
    "        'random_X_test_corr': test_corr_X_rand, \n",
    "        'random_X_test_mse': test_mse_X_rand, \n",
    "        'linear_baseline_test_corr': test_corr_linear, \n",
    "        'linear_baseline_test_mse': test_mse_linear, \n",
    "        })\n",
    "    best_res_df = pd.DataFrame(results)\n",
    "#     res[k] = {'test': y_test, 'pred': y_test_pred, 'train': y_train}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b40ae23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_df = best_res_df[[col for col in best_res_df if 'test' in col or col == 'fold']]\n",
    "viz_df_corr = viz_df[[col for col in viz_df if 'corr' in col]]\n",
    "viz_df_mse = viz_df[[col for col in viz_df if 'mse' in col]]\n",
    "viz_dfs = {'Pearson Correlation': viz_df_corr, \n",
    "          'Mean Squared Error': viz_df_mse}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f3008a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols = 2, figsize = (10,5))\n",
    "\n",
    "for i, (metric, viz_df) in enumerate(viz_dfs.items()):\n",
    "    viz_df = pd.melt(viz_df, value_name=metric, var_name = 'Model Type')\n",
    "    sns.violinplot(data = viz_df, x = 'Model Type', y = metric, ax = ax[i])\n",
    "    ax[i].set_xticklabels(ax[i].get_xticklabels(), \n",
    "                     rotation = 30, ha = 'center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd10201",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metastatic_potential]",
   "language": "python",
   "name": "conda-env-metastatic_potential-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
