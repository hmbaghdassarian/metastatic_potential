{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcb1ad68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nobackup/users/hmbaghda/Software/miniforge3/envs/metastatic_potential/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pathlib\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import CmaEsSampler, TPESampler, RandomSampler\n",
    "from optuna.distributions import CategoricalDistribution\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c0dd2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/nobackup/users/hmbaghda/metastatic_potential/'\n",
    "random_state = 42\n",
    "\n",
    "n_cores = 80\n",
    "os.environ[\"OMP_NUM_THREADS\"] = str(n_cores)\n",
    "os.environ[\"MKL_NUM_THREADS\"] = str(n_cores)\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = str(n_cores)\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = str(n_cores)\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = str(n_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ccf071d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_pickled_object(object_, file_name: str) -> None:\n",
    "    if '.' in file_name:\n",
    "        p = pathlib.Path(file_name)\n",
    "        extensions = \"\".join(p.suffixes)\n",
    "        file_name = str(p).replace(extensions, '.pickle')\n",
    "    else:\n",
    "        file_name = file_name + '.pickle'\n",
    "\n",
    "    with open(file_name, 'wb') as handle:\n",
    "        pickle.dump(object_, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6133b0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection transformer\n",
    "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, method='top_n_cv', n_features=None):\n",
    "        if method not in ['top_n_cv']:#, 'all_features']:\n",
    "            raise ValueError('Incorrect feature selection method implemented')\n",
    "        self.method = method\n",
    "        self.n_features = n_features\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if self.method == 'top_n_cv':\n",
    "            self.coefficient_of_variation_ = np.std(X, axis=0) / np.mean(X, axis=0)\n",
    "            self.top_indices_ = np.argsort(self.coefficient_of_variation_)[::-1][:self.n_features]\n",
    "#         elif self.method == 'all_features':\n",
    "#             self.top_indices_ = range(X.shape[1])\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X[:, self.top_indices_]\n",
    "    \n",
    "class MeanCenterer(TransformerMixin, BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "#         self.mean_ = np.mean(X, axis=0)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X - np.mean(X, axis=0)\n",
    "    \n",
    "def pearson_corr_scorer(y_true, y_pred):\n",
    "    return pearsonr(y_true, y_pred)[0]\n",
    "\n",
    "class PLSRegression_X(PLSRegression):\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = super().transform(X, y)\n",
    "        if isinstance(X_transformed, tuple):\n",
    "            X_transformed = X_transformed[0]\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d627a1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridSampler(optuna.samplers.BaseSampler):\n",
    "    def __init__(self, primary_sampler, fallback_sampler):\n",
    "        self.primary_sampler = primary_sampler  # e.g., CmaEsSampler\n",
    "        self.fallback_sampler = fallback_sampler  # e.g., TPESampler\n",
    "\n",
    "    def infer_relative_search_space(self, study, trial):\n",
    "        # Let the primary sampler define the relative search space\n",
    "        return self.primary_sampler.infer_relative_search_space(study, trial)\n",
    "\n",
    "    def sample_relative(self, study, trial, search_space):\n",
    "        # Let the primary sampler handle relative sampling\n",
    "        return self.primary_sampler.sample_relative(study, trial, search_space)\n",
    "\n",
    "    def sample_independent(self, study, trial, param_name, param_distribution):\n",
    "        # Use the fallback sampler for unsupported parameter types\n",
    "        if isinstance(param_distribution, CategoricalDistribution):\n",
    "            return self.fallback_sampler.sample_independent(study, trial, param_name, param_distribution)\n",
    "        # Default to the primary sampler\n",
    "        return self.primary_sampler.sample_independent(study, trial, param_name, param_distribution)\n",
    "\n",
    "class RandomTPESampler(TPESampler):\n",
    "    def __init__(self, exploration_sampler, exploration_freq=20, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.exploration_sampler = exploration_sampler\n",
    "        self.exploration_freq = exploration_freq\n",
    "\n",
    "    def sample_independent(self, study, trial, param_name, param_distribution):\n",
    "        # Use the exploration_sampler periodically\n",
    "        if trial.number % self.exploration_freq == 0:\n",
    "            return self.exploration_sampler.sample_independent(study, trial, param_name, param_distribution)\n",
    "        # Default to TPE\n",
    "        return super().sample_independent(study, trial, param_name, param_distribution)\n",
    "\n",
    "\n",
    "def optuna_objective(trial, X, y, inner_cv, n_cores, random_state):\n",
    "    # Define feature reduction/selection method\n",
    "    feature_step = trial.suggest_categorical(\"feature_step\", [\"PLS\", \"PCA\", \"FeatureSelector\"])\n",
    "\n",
    "    if feature_step == \"PLS\":\n",
    "        steps = [\n",
    "            (\"mean_centering\", MeanCenterer()),\n",
    "            (\"feature_reduction\", PLSRegression_X(n_components=trial.suggest_categorical(\"PLS__n_components\", [2, 5, 10, 25, 50, 100]))),\n",
    "        ]\n",
    "    elif feature_step == \"PCA\":\n",
    "        steps = [\n",
    "            (\"mean_centering\", MeanCenterer()),\n",
    "            (\"feature_reduction\", PCA(n_components=trial.suggest_categorical(\"PCA__n_components\", [2, 5, 10, 25, 50, 100]), random_state=random_state)),\n",
    "        ]\n",
    "    elif feature_step == \"FeatureSelector\":\n",
    "        steps = [\n",
    "            (\"feature_reduction\", FeatureSelector(method=\"top_n_cv\", n_features=trial.suggest_categorical(\"FeatureSelector__n_features\", [250, 500, 1000, 5000, 17879]))),\n",
    "            (\"mean_centering\", MeanCenterer()),\n",
    "        ]\n",
    "    # Define model\n",
    "    model_type = trial.suggest_categorical(\"model_type\", [\"SVR\", \"RFR\"])\n",
    "    if model_type == \"SVR\":\n",
    "        steps.append((\"model\", SVR(\n",
    "            kernel=trial.suggest_categorical(\"SVR__kernel\", [\"rbf\", \"poly\"]),\n",
    "            C=trial.suggest_float(\"SVR__C\", 1e-4, 1e2, log = True),\n",
    "            degree=trial.suggest_int(\"SVR__degree\", 2, 4),\n",
    "#             coef0=trial.suggest_uniform(\"SVR__coef0\", 0, 2),\n",
    "            gamma=0.001\n",
    "        )))\n",
    "    elif model_type == \"RFR\":\n",
    "        steps.append((\"model\", RandomForestRegressor(\n",
    "            n_estimators=trial.suggest_int(\"RFR__n_estimators\", 300, 1600, step=400),\n",
    "            max_features=trial.suggest_categorical(\"RFR__max_features\", [\"sqrt\", \"log2\", 0.5, 0.75, 1]),\n",
    "            max_samples=trial.suggest_categorical(\"RFR__max_samples\", [0.25, 0.5, 0.75, None]),\n",
    "            max_depth=trial.suggest_categorical(\"RFR__max_depth\", [None, 10, 25, 50, 100, 200]),\n",
    "            random_state=random_state,\n",
    "            n_jobs=int(n_cores/inner_cv.n_splits)\n",
    "        )))\n",
    "\n",
    "    # Create the pipeline\n",
    "    pipeline = Pipeline(steps)\n",
    "\n",
    "    # Evaluate with cross-validation\n",
    "    mse = -cross_val_score(pipeline, X, y, \n",
    "                           cv=inner_cv, \n",
    "                           scoring=\"neg_mean_squared_error\", \n",
    "                           n_jobs=inner_cv.n_splits).mean()\n",
    "\n",
    "#     for fold_idx, (train_idx, val_idx) in enumerate(inner_cv.split(X, y)):\n",
    "#         X_train, X_val = X[train_idx], X[val_idx]\n",
    "#         y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "#         # Train and evaluate the pipeline on the current fold\n",
    "#         pipeline.fit(X_train, y_train)\n",
    "#         y_val_pred = pipeline.predict(X_val)\n",
    "#         mse = mean_squared_error(y_val, y_val_pred)\n",
    "\n",
    "#         # Store the MSE for this fold\n",
    "#         mse_scores.append(mse)\n",
    "\n",
    "#         # Report intermediate result to Optuna\n",
    "#         trial.report(np.mean(mse_scores), step=fold_idx)\n",
    "\n",
    "#         # Check if the trial should be pruned\n",
    "#         if trial.should_prune():\n",
    "#             raise optuna.exceptions.TrialPruned()\n",
    "    \n",
    "#     return np.mean(mse_scores)\n",
    "\n",
    "    return mse\n",
    "\n",
    "\n",
    "def generate_best_pipeline(study):\n",
    "    best_params = study.best_params\n",
    "    steps = []\n",
    "    if best_params[\"feature_step\"] == \"PLS\":\n",
    "        steps.append((\"mean_centering\", MeanCenterer()))\n",
    "        steps.append((\"feature_reduction\", PLSRegression_X(n_components=best_params[\"PLS__n_components\"])))\n",
    "    elif best_params[\"feature_step\"] == \"PCA\":\n",
    "        steps.append((\"mean_centering\", MeanCenterer()))\n",
    "        steps.append((\"feature_reduction\", PCA(n_components=best_params[\"PCA__n_components\"], random_state=random_state)))\n",
    "    elif best_params[\"feature_step\"] == \"FeatureSelector\":\n",
    "        steps.append((\"feature_reduction\", FeatureSelector(method=\"top_n_cv\", n_features=best_params[\"FeatureSelector__n_features\"])))\n",
    "        steps.append((\"mean_centering\", MeanCenterer()))\n",
    "\n",
    "    if \"SVR__kernel\" in best_params:\n",
    "        steps.append((\"model\", SVR(\n",
    "            kernel=best_params[\"SVR__kernel\"],\n",
    "            C=best_params[\"SVR__C\"],\n",
    "            degree=best_params[\"SVR__degree\"],\n",
    "#             coef0=best_params[\"SVR__coef0\"],\n",
    "            gamma=0.001\n",
    "        )))\n",
    "    elif \"RFR__n_estimators\" in best_params:\n",
    "        steps.append((\"model\", RandomForestRegressor(\n",
    "            n_estimators=best_params[\"RFR__n_estimators\"],\n",
    "            max_features=best_params[\"RFR__max_features\"],\n",
    "            max_samples=best_params[\"RFR__max_samples\"],\n",
    "            max_depth=best_params[\"RFR__max_depth\"],\n",
    "            random_state=random_state,\n",
    "            n_jobs=n_cores\n",
    "        )))\n",
    "\n",
    "    best_pipeline = Pipeline(steps)\n",
    "    return best_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0b152e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(os.path.join(data_path, 'processed',  'expr.csv'), index_col = 0).T.values\n",
    "y = pd.read_csv(os.path.join(data_path, 'processed', 'metastatic_potential.csv'), index_col = 0).values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23e5c234",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_folds=10\n",
    "inner_folds=5\n",
    "n_trials = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5344f6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nobackup/users/hmbaghda/Software/miniforge3/envs/metastatic_potential/lib/python3.13/site-packages/optuna/_experimental.py:31: ExperimentalWarning: Argument ``restart_strategy`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cmaes_sampler = CmaEsSampler(seed=random_state, \n",
    "                             warn_independent_sampling=False, \n",
    "                            restart_strategy='bipop')\n",
    "\n",
    "exploration_sampler = RandomSampler(seed=random_state)\n",
    "tpe_sampler = RandomTPESampler(seed=random_state, \n",
    "                               n_startup_trials = 25,\n",
    "                               exploration_sampler = exploration_sampler, \n",
    "                               exploration_freq=20 # randomly sample every n trials\n",
    "                              )\n",
    "# tpe_sampler = TPESampler(seed=random_state, \n",
    "#                         n_startup_trials = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5636eb4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.3542783142850661)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# outer_cv = KFold(n_splits=outer_folds, shuffle=True, random_state=random_state)\n",
    "# inner_cv = KFold(n_splits=inner_folds, shuffle=True, random_state=random_state)\n",
    "\n",
    "# results = []\n",
    "# for k, (train_idx, test_idx) in enumerate(outer_cv.split(X, y)):\n",
    "#     print(str(k))\n",
    "#     X_train, X_test = X[train_idx], X[test_idx]\n",
    "#     y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    \n",
    "#     pruner = optuna.pruners.SuccessiveHalvingPruner()\n",
    "#     study = optuna.create_study(direction=\"minimize\", \n",
    "#                                 sampler=HybridSampler(primary_sampler=cmaes_sampler, fallback_sampler=tpe_sampler), \n",
    "#                                pruner = pruner, \n",
    "#                                study_name = '{}_optuna'.format(k))\n",
    "#     study.optimize(\n",
    "#         lambda trial: optuna_objective(trial, X_train, y_train, inner_cv, n_cores, random_state),\n",
    "#         n_trials=n_trials, \n",
    "#         catch=(ValueError,)\n",
    "#     )\n",
    "#     write_pickled_object(study, os.path.join(data_path, 'interim', study.study_name + '.pickle'))\n",
    "        \n",
    "#     best_pipeline = generate_best_pipeline(study)\n",
    "#     best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "#     y_train_pred = best_pipeline.predict(X_train)\n",
    "#     y_test_pred = best_pipeline.predict(X_test)\n",
    "\n",
    "#     train_corr = pearsonr(y_train, y_train_pred)[0]\n",
    "#     test_corr = pearsonr(y_test, y_test_pred)[0]\n",
    "\n",
    "#     results.append({\n",
    "#         \"fold\": k,\n",
    "#         \"train_corr\": train_corr,\n",
    "#         \"test_corr\": test_corr,\n",
    "#         \"best_params\": study.best_params,\n",
    "#         \"inner_cv\": study.trials_dataframe()\n",
    "#         })\n",
    "#     res_df = pd.DataFrame(results)\n",
    "#     res_df.to_csv(os.path.join(data_path, 'interim', 'pipeline.csv'))\n",
    "\n",
    "res = pd.read_csv(os.path.join(data_path, 'interim', 'pipeline.csv'), index_col = 0)\n",
    "res.test_corr.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee329bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>train_corr</th>\n",
       "      <th>test_corr</th>\n",
       "      <th>best_params</th>\n",
       "      <th>inner_cv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.994878</td>\n",
       "      <td>0.272630</td>\n",
       "      <td>{'feature_step': 'PLS', 'PLS__n_components': 1...</td>\n",
       "      <td>number     value             datetime_sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.959903</td>\n",
       "      <td>0.313248</td>\n",
       "      <td>{'feature_step': 'PLS', 'PLS__n_components': 1...</td>\n",
       "      <td>number     value             datetime_sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.976810</td>\n",
       "      <td>0.489579</td>\n",
       "      <td>{'feature_step': 'PLS', 'PLS__n_components': 2...</td>\n",
       "      <td>number     value             datetime_sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.876442</td>\n",
       "      <td>0.217207</td>\n",
       "      <td>{'feature_step': 'PLS', 'PLS__n_components': 2...</td>\n",
       "      <td>number     value             datetime_sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.995946</td>\n",
       "      <td>0.470749</td>\n",
       "      <td>{'feature_step': 'PLS', 'PLS__n_components': 2...</td>\n",
       "      <td>number     value             datetime_sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.991274</td>\n",
       "      <td>0.332673</td>\n",
       "      <td>{'feature_step': 'FeatureSelector', 'FeatureSe...</td>\n",
       "      <td>number     value             datetime_sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.965412</td>\n",
       "      <td>0.465452</td>\n",
       "      <td>{'feature_step': 'PLS', 'PLS__n_components': 2...</td>\n",
       "      <td>number     value             datetime_sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.954671</td>\n",
       "      <td>0.192457</td>\n",
       "      <td>{'feature_step': 'PCA', 'PCA__n_components': 5...</td>\n",
       "      <td>number     value             datetime_sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.986323</td>\n",
       "      <td>0.542248</td>\n",
       "      <td>{'feature_step': 'PLS', 'PLS__n_components': 2...</td>\n",
       "      <td>number     value             datetime_sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.999242</td>\n",
       "      <td>0.246540</td>\n",
       "      <td>{'feature_step': 'FeatureSelector', 'FeatureSe...</td>\n",
       "      <td>number     value             datetime_sta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  train_corr  test_corr  \\\n",
       "0     0    0.994878   0.272630   \n",
       "1     1    0.959903   0.313248   \n",
       "2     2    0.976810   0.489579   \n",
       "3     3    0.876442   0.217207   \n",
       "4     4    0.995946   0.470749   \n",
       "5     5    0.991274   0.332673   \n",
       "6     6    0.965412   0.465452   \n",
       "7     7    0.954671   0.192457   \n",
       "8     8    0.986323   0.542248   \n",
       "9     9    0.999242   0.246540   \n",
       "\n",
       "                                         best_params  \\\n",
       "0  {'feature_step': 'PLS', 'PLS__n_components': 1...   \n",
       "1  {'feature_step': 'PLS', 'PLS__n_components': 1...   \n",
       "2  {'feature_step': 'PLS', 'PLS__n_components': 2...   \n",
       "3  {'feature_step': 'PLS', 'PLS__n_components': 2...   \n",
       "4  {'feature_step': 'PLS', 'PLS__n_components': 2...   \n",
       "5  {'feature_step': 'FeatureSelector', 'FeatureSe...   \n",
       "6  {'feature_step': 'PLS', 'PLS__n_components': 2...   \n",
       "7  {'feature_step': 'PCA', 'PCA__n_components': 5...   \n",
       "8  {'feature_step': 'PLS', 'PLS__n_components': 2...   \n",
       "9  {'feature_step': 'FeatureSelector', 'FeatureSe...   \n",
       "\n",
       "                                            inner_cv  \n",
       "0       number     value             datetime_sta...  \n",
       "1       number     value             datetime_sta...  \n",
       "2       number     value             datetime_sta...  \n",
       "3       number     value             datetime_sta...  \n",
       "4       number     value             datetime_sta...  \n",
       "5       number     value             datetime_sta...  \n",
       "6       number     value             datetime_sta...  \n",
       "7       number     value             datetime_sta...  \n",
       "8       number     value             datetime_sta...  \n",
       "9       number     value             datetime_sta...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfca240",
   "metadata": {},
   "source": [
    "Select a best consensus model and re-run on new folds to see the performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87ff1476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature_step': 'PLS', 'PLS__n_components': 10, 'model_type': 'RFR', 'RFR__n_estimators': 300, 'RFR__max_features': 'sqrt', 'RFR__max_samples': None, 'RFR__max_depth': 200}\n",
      "------------------------------------------------------\n",
      "{'feature_step': 'PLS', 'PLS__n_components': 10, 'model_type': 'RFR', 'RFR__n_estimators': 300, 'RFR__max_features': 0.75, 'RFR__max_samples': 0.25, 'RFR__max_depth': 10}\n",
      "------------------------------------------------------\n",
      "{'feature_step': 'PLS', 'PLS__n_components': 25, 'model_type': 'RFR', 'RFR__n_estimators': 300, 'RFR__max_features': 'sqrt', 'RFR__max_samples': 0.25, 'RFR__max_depth': 10}\n",
      "------------------------------------------------------\n",
      "{'feature_step': 'PLS', 'PLS__n_components': 2, 'model_type': 'RFR', 'RFR__n_estimators': 1500, 'RFR__max_features': 'sqrt', 'RFR__max_samples': 0.25, 'RFR__max_depth': 200}\n",
      "------------------------------------------------------\n",
      "{'feature_step': 'PLS', 'PLS__n_components': 25, 'model_type': 'RFR', 'RFR__n_estimators': 1100, 'RFR__max_features': 'sqrt', 'RFR__max_samples': None, 'RFR__max_depth': 10}\n",
      "------------------------------------------------------\n",
      "{'feature_step': 'FeatureSelector', 'FeatureSelector__n_features': 5000, 'model_type': 'RFR', 'RFR__n_estimators': 300, 'RFR__max_features': 0.75, 'RFR__max_samples': None, 'RFR__max_depth': 25}\n",
      "------------------------------------------------------\n",
      "{'feature_step': 'PLS', 'PLS__n_components': 25, 'model_type': 'RFR', 'RFR__n_estimators': 700, 'RFR__max_features': 0.5, 'RFR__max_samples': 0.25, 'RFR__max_depth': None}\n",
      "------------------------------------------------------\n",
      "{'feature_step': 'PCA', 'PCA__n_components': 50, 'model_type': 'RFR', 'RFR__n_estimators': 300, 'RFR__max_features': 0.5, 'RFR__max_samples': 0.5, 'RFR__max_depth': 25}\n",
      "------------------------------------------------------\n",
      "{'feature_step': 'PLS', 'PLS__n_components': 25, 'model_type': 'RFR', 'RFR__n_estimators': 300, 'RFR__max_features': 'log2', 'RFR__max_samples': 0.5, 'RFR__max_depth': 200}\n",
      "------------------------------------------------------\n",
      "{'feature_step': 'FeatureSelector', 'FeatureSelector__n_features': 1000, 'model_type': 'SVR', 'SVR__kernel': 'rbf', 'SVR__C': 25.126890108305947, 'SVR__degree': 3}\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for bp in res.best_params:\n",
    "    print(bp)\n",
    "    print('------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74a9f57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_steps = [\n",
    "    (\"mean_centering\", MeanCenterer()),\n",
    "    (\"feature_reduction\", PLSRegression_X(n_components=10, scale = True)),\n",
    "]\n",
    "best_steps.append((\"model\", RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    max_features='sqrt',\n",
    "    max_samples=0.25,\n",
    "    max_depth=10, # tie between 200 and 10\n",
    "    random_state=random_state,\n",
    "    n_jobs=n_cores\n",
    ")))\n",
    "best_pipeline = Pipeline(best_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27c0006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(os.path.join(data_path, 'processed',  'expr.csv'), index_col = 0).T.values\n",
    "y = pd.read_csv(os.path.join(data_path, 'processed', 'metastatic_potential.csv'), index_col = 0).values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d82e3155",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:12,  1.30s/it]\n"
     ]
    }
   ],
   "source": [
    "outer_cv = KFold(n_splits=10, shuffle=True, random_state=random_state+1)\n",
    "\n",
    "\n",
    "res = {}\n",
    "\n",
    "results = []\n",
    "for k, (train_idx, test_idx) in tqdm(enumerate(outer_cv.split(X, y))):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = best_pipeline.predict(X_train)\n",
    "    y_test_pred = best_pipeline.predict(X_test)\n",
    "\n",
    "    train_corr = pearsonr(y_train, y_train_pred)[0]\n",
    "    test_corr = pearsonr(y_test, y_test_pred)[0]\n",
    "\n",
    "    results.append({\n",
    "        \"fold\": k,\n",
    "        \"train_corr\": train_corr,\n",
    "        \"test_corr\": test_corr,\n",
    "        })\n",
    "    best_res_df = pd.DataFrame(results)\n",
    "    res[k] = {'test': y_test, 'pred': y_test_pred, 'train': y_train}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "edb5c4e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>train_corr</th>\n",
       "      <th>test_corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.973936</td>\n",
       "      <td>0.322485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.979850</td>\n",
       "      <td>0.520824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.973400</td>\n",
       "      <td>0.268299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.975479</td>\n",
       "      <td>0.570978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.970206</td>\n",
       "      <td>-0.012856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.978579</td>\n",
       "      <td>0.379738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.973479</td>\n",
       "      <td>0.372561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.971110</td>\n",
       "      <td>0.713619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.971442</td>\n",
       "      <td>0.513119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.976556</td>\n",
       "      <td>0.291682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  train_corr  test_corr\n",
       "0     0    0.973936   0.322485\n",
       "1     1    0.979850   0.520824\n",
       "2     2    0.973400   0.268299\n",
       "3     3    0.975479   0.570978\n",
       "4     4    0.970206  -0.012856\n",
       "5     5    0.978579   0.379738\n",
       "6     6    0.973479   0.372561\n",
       "7     7    0.971110   0.713619\n",
       "8     8    0.971442   0.513119\n",
       "9     9    0.976556   0.291682"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "403f815a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.3940447207902385)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_res_df.test_corr.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metastatic_potential]",
   "language": "python",
   "name": "conda-env-metastatic_potential-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
