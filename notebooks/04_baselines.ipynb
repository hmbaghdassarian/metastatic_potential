{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d06b519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from tqdm import tqdm \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "import scipy.stats as stats\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92e1eda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "n_cores = 20\n",
    "data_path = '/nobackup/users/hmbaghda/metastatic_potential/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d915b7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val = pd.read_csv(os.path.join(data_path, 'interim', 'X_train_val_selected.csv'), index_col = 0)\n",
    "y_train_val = pd.read_csv(os.path.join(data_path, 'interim', 'y_train_val.csv'), index_col = 0)\n",
    "\n",
    "X_test = pd.read_csv(os.path.join(data_path, 'interim', 'X_test_selected.csv'), index_col = 0)\n",
    "y_test = pd.read_csv(os.path.join(data_path, 'interim', 'y_test.csv'), index_col = 0)\n",
    "y_test = y_test.values.flatten()\n",
    "\n",
    "res = pd.read_csv(os.path.join(data_path, 'interim', 'hyperparams.csv'), index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "612e8eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scp hmbaghda@satori-login-002.mit.edu:/nobackup/users/hmbaghda/metastatic_potential/interim/X_train_val_selected.csv .\n",
      "scp hmbaghda@satori-login-002.mit.edu:/nobackup/users/hmbaghda/metastatic_potential/interim/y_train_val.csv .\n",
      "scp hmbaghda@satori-login-002.mit.edu:/nobackup/users/hmbaghda/metastatic_potential/interim/X_test_selected.csv .\n",
      "scp hmbaghda@satori-login-002.mit.edu:/nobackup/users/hmbaghda/metastatic_potential/interim/y_test.csv .\n",
      "scp hmbaghda@satori-login-002.mit.edu:/nobackup/users/hmbaghda/metastatic_potential/interim/hyperparams.csv .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fns = [os.path.join(data_path, 'interim', 'X_train_val_selected.csv'), \n",
    "#        os.path.join(data_path, 'interim', 'y_train_val.csv'), \n",
    "#        os.path.join(data_path, 'interim', 'X_test_selected.csv'), \n",
    "#        os.path.join(data_path, 'interim', 'y_test.csv'), \n",
    "#       os.path.join(data_path, 'interim', 'hyperparams.csv')]\n",
    "# for fn in fns:\n",
    "#     print('scp hmbaghda@satori-login-002.mit.edu:' + fn + ' .')\n",
    "# print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0797842f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': np.int64(850),\n",
       " 'max_features': 1,\n",
       " 'max_samples': None,\n",
       " 'max_depth': 25,\n",
       " 'min_samples_split': np.int64(2),\n",
       " 'min_samples_leaf': np.int64(1)}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_ = res.infer_objects(copy = False).fillna('None')\n",
    "hyperparam_names = ['n_estimators', 'max_features', 'max_samples', 'max_depth', 'min_samples_split', 'min_samples_leaf']\n",
    "best_mse_params = list(res_.groupby(hyperparam_names)['mse'].mean().idxmin())\n",
    "best_mse_params = [x if x != 'None' else None for x in best_mse_params]\n",
    "best_mse_params = dict(zip(hyperparam_names, best_mse_params))\n",
    "\n",
    "for hp in ['max_features', 'max_depth']:\n",
    "    best_mse_params[hp] = int(best_mse_params[hp])\n",
    "\n",
    "best_mse_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "540d2794",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:36,  3.61s/it]\n"
     ]
    }
   ],
   "source": [
    "rf_mse = []\n",
    "rf_pearson = []\n",
    "rf_spearman = []\n",
    "\n",
    "baseline_mse = []\n",
    "baseline_pearson = []\n",
    "baseline_spearman = []\n",
    "\n",
    "linear_mse = []\n",
    "linear_pearson = []\n",
    "linear_spearman = []\n",
    "\n",
    "n_splits = 10\n",
    "kf = KFold(n_splits=n_splits, shuffle = True, random_state = seed)\n",
    "y_predictions = pd.DataFrame(columns = range(n_splits), index = range(y_test.shape[0]))\n",
    "\n",
    "for i, (train_index, val_index) in tqdm(enumerate(kf.split(X_train_val, y_train_val))): # iterate through folds for train-val split and do the below loop for each fold\n",
    "\n",
    "    X_train, _ = X_train_val.iloc[train_index], X_train_val.iloc[val_index]\n",
    "    y_train, _ = y_train_val.iloc[train_index], y_train_val.iloc[val_index]\n",
    "    y_train = y_train.values.flatten()\n",
    "\n",
    "    # ACTUAL MODEL\n",
    "    model = RandomForestRegressor(n_estimators = best_mse_params['n_estimators'],\n",
    "                                  max_features = best_mse_params['max_features'],\n",
    "                                  max_samples = best_mse_params['max_samples'],\n",
    "                                  max_depth = best_mse_params['max_depth'],\n",
    "                                  min_samples_split = best_mse_params['min_samples_split'],\n",
    "                                  min_samples_leaf = best_mse_params['min_samples_leaf'],\n",
    "                                  n_jobs = n_cores,\n",
    "                                  random_state = seed)\n",
    "    # # training on shuffled features (random baseline)\n",
    "    # y_train_shuffled = y_train.values.reshape(-1).copy()\n",
    "    # np.random.shuffle(y_train_shuffled)\n",
    "    model.fit(X_train, y_train) # fit on the shuffled data\n",
    "\n",
    "    # predict on non-shuffled features\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # store results\n",
    "    y_predictions.iloc[:, i] = y_pred\n",
    "    rf_mse.append(mean_squared_error(y_test, y_pred))\n",
    "    rf_pearson.append(pearsonr(y_test, y_pred))\n",
    "    rf_spearman.append(stats.spearmanr(y_test, y_pred))\n",
    "\n",
    "    # RANDOM BASELINE\n",
    "    model_rand = RandomForestRegressor(n_estimators = best_mse_params['n_estimators'],\n",
    "                                  max_features = best_mse_params['max_features'],\n",
    "                                  max_samples = best_mse_params['max_samples'],\n",
    "                                  max_depth = best_mse_params['max_depth'],\n",
    "                                  min_samples_split = best_mse_params['min_samples_split'],\n",
    "                                  min_samples_leaf = best_mse_params['min_samples_leaf'],\n",
    "                                    random_state = seed)\n",
    "\n",
    "    # training on shuffled features (random baseline)\n",
    "    y_train_shuffled = y_train.copy()\n",
    "    np.random.shuffle(y_train_shuffled)\n",
    "    model_rand.fit(X_train, y_train_shuffled) # fit on the shuffled data\n",
    "\n",
    "    # predict on non-shuffled features\n",
    "    y_pred_rand = model_rand.predict(X_test)\n",
    "\n",
    "    # TO DO get mse and pearsons comparing y_pred_rand to y_test\n",
    "    baseline_mse.append(mean_squared_error(y_test, y_pred_rand))\n",
    "    baseline_pearson.append(pearsonr(y_test, y_pred_rand))\n",
    "    baseline_spearman.append(stats.spearmanr(y_test, y_pred_rand))\n",
    "\n",
    "\n",
    "   # LINEAR BASELINE\n",
    "    model_linear = LinearRegression()\n",
    "    model_linear.fit(X_train, y_train)\n",
    "\n",
    "    # predict on test values\n",
    "    y_pred_linear = model_linear.predict(X_test)\n",
    "\n",
    "    # get stats comparing predicted to test values\n",
    "    linear_mse.append(mean_squared_error(y_test, y_pred_linear))\n",
    "    linear_pearson.append(pearsonr(y_test, y_pred_linear)) # flatten to 1D arrays\n",
    "    linear_spearman.append(stats.spearmanr(y_test, y_pred_linear))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6ad7e949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SignificanceResult(statistic=np.float64(0.18976256552574777), pvalue=np.float64(0.2065437533858929))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.spearmanr(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e3fbce9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.56093728, -0.94204902, -1.6349899 , -1.41862062, -1.76053958,\n",
       "       -1.18147114, -1.8719264 , -1.37790161, -1.94459033, -1.71356756,\n",
       "       -1.56643192, -2.20652747, -1.46287334, -1.16829814, -1.29843077,\n",
       "       -1.04836812, -1.89047599, -2.03876644, -0.78611356, -1.28246168,\n",
       "       -2.28050832, -1.70636575, -1.46087174, -1.63282035, -1.67581432,\n",
       "       -1.69941386, -1.89251902, -1.68891085, -1.79536695, -1.68181596,\n",
       "       -0.98974806, -1.64609567, -1.61547171, -1.50081229, -1.78545324,\n",
       "       -1.75446019, -1.71656779, -1.96649416, -1.72883712, -2.01120151,\n",
       "       -1.24736955, -2.06782622, -1.49713663, -1.62209141, -1.38066736,\n",
       "       -0.89321234])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0796644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.68769417, -0.82605535, -1.69000056, -1.3477291 , -1.70552701,\n",
       "       -1.18819499, -1.76194308, -1.44865451, -1.93319881, -1.76671943,\n",
       "       -1.48143044, -2.0771705 , -1.39989795, -1.30339735, -1.34194877,\n",
       "       -1.00936808, -1.88674267, -2.04838034, -0.7545633 , -1.26668222,\n",
       "       -2.2501269 , -1.62513068, -1.46957948, -1.62690455, -1.67585733,\n",
       "       -1.59833999, -1.79910003, -1.63450723, -1.74151919, -1.6270904 ,\n",
       "       -0.95610886, -1.75031271, -1.61299769, -1.40687082, -1.73162797,\n",
       "       -1.74344652, -1.73968625, -2.00004862, -1.66168871, -1.9598469 ,\n",
       "       -1.19895341, -1.97431925, -1.40940372, -1.50373621, -1.34616631,\n",
       "       -1.03315551])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de5d4c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metastatic_potential]",
   "language": "python",
   "name": "conda-env-metastatic_potential-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
